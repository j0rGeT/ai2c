#!/usr/bin/env python3
"""
AIå†…å®¹åˆ›ä½œç³»ç»Ÿ - ä¸»ç¨‹åº
æ”¯æŒæ–‡ç« å†™ä½œã€è¯­éŸ³è¯†åˆ«ã€è§†é¢‘ç”Ÿæˆã€æç¤ºè¯ä¼˜åŒ–ç­‰åŠŸèƒ½
"""

import os
import sys
import argparse
import json
from datetime import datetime
from typing import Dict, Any

from src.content_generation.content_generator import ContentGenerator
from src.speech_recognition.speech_processor import SpeechProcessor
from src.prompt_optimization.prompt_optimizer import PromptOptimizer

# è§†é¢‘ç”Ÿæˆå™¨çš„å¯é€‰å¯¼å…¥
try:
    from src.video_generation.video_generator import VideoGenerator
    VIDEO_GENERATION_AVAILABLE = True
except ImportError:
    VIDEO_GENERATION_AVAILABLE = False
    VideoGenerator = None

# å›¾åƒç”Ÿæˆå™¨çš„å¯é€‰å¯¼å…¥
try:
    from src.image_generation.text_to_image import TextToImageGenerator
    from src.image_generation.image_to_video import ImageToVideoGenerator
    from src.image_generation.image_editor import ImageEditor
    IMAGE_GENERATION_AVAILABLE = True
except ImportError:
    IMAGE_GENERATION_AVAILABLE = False
    TextToImageGenerator = None
    ImageToVideoGenerator = None
    ImageEditor = None

class AI2CSystem:
    def __init__(self):
        self.content_generator = ContentGenerator()
        self.speech_processor = SpeechProcessor()
        self.prompt_optimizer = PromptOptimizer()
        
        # è§†é¢‘ç”Ÿæˆå™¨çš„å¯é€‰åˆå§‹åŒ–
        if VIDEO_GENERATION_AVAILABLE:
            self.video_generator = VideoGenerator()
        else:
            self.video_generator = None
        
        # å›¾åƒç”Ÿæˆå™¨çš„å¯é€‰åˆå§‹åŒ–
        if IMAGE_GENERATION_AVAILABLE:
            self.text_to_image = TextToImageGenerator()
            self.image_to_video = ImageToVideoGenerator()
            self.image_editor = ImageEditor()
        else:
            self.text_to_image = None
            self.image_to_video = None
            self.image_editor = None
    
    def generate_article(self, topic: str, style: str = "informative", length: str = "medium", provider: str = None):
        print(f"æ­£åœ¨ç”Ÿæˆå…³äº'{topic}'çš„æ–‡ç« ...")
        
        try:
            result = self.content_generator.generate_article(topic, style, length, provider)
            filepath = self.content_generator.save_content(result)
            
            print(f"âœ… æ–‡ç« ç”ŸæˆæˆåŠŸ!")
            print(f"ğŸ“„ æ–‡ä»¶ä¿å­˜è‡³: {filepath}")
            print(f"ğŸ“Š å­—æ•°ç»Ÿè®¡: {result['metadata']['word_count']} å­—")
            
            return result
        except Exception as e:
            print(f"âŒ æ–‡ç« ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    def generate_novel_chapter(self, plot: str, characters: str = "", setting: str = "", chapter_number: int = 1, provider: str = None):
        print(f"æ­£åœ¨ç”Ÿæˆç¬¬{chapter_number}ç« å°è¯´...")
        
        try:
            result = self.content_generator.generate_novel_chapter(plot, characters, setting, chapter_number, provider)
            filepath = self.content_generator.save_content(result)
            
            print(f"âœ… å°è¯´ç« èŠ‚ç”ŸæˆæˆåŠŸ!")
            print(f"ğŸ“„ æ–‡ä»¶ä¿å­˜è‡³: {filepath}")
            print(f"ğŸ“Š å­—æ•°ç»Ÿè®¡: {result['metadata']['word_count']} å­—")
            
            return result
        except Exception as e:
            print(f"âŒ å°è¯´ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    def generate_story_outline(self, theme: str, genre: str = "ç°ä»£", length: str = "ä¸­ç¯‡", provider: str = None):
        print(f"æ­£åœ¨ç”Ÿæˆ'{theme}'å°è¯´å¤§çº²...")
        
        try:
            result = self.content_generator.generate_story_outline(theme, genre, length, provider)
            filepath = self.content_generator.save_content(result)
            
            print(f"âœ… å°è¯´å¤§çº²ç”ŸæˆæˆåŠŸ!")
            print(f"ğŸ“„ æ–‡ä»¶ä¿å­˜è‡³: {filepath}")
            
            return result
        except Exception as e:
            print(f"âŒ å¤§çº²ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    def process_audio(self, audio_path: str, language: str = "zh", summary_type: str = "è¯¦ç»†"):
        if not os.path.exists(audio_path):
            print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
            return None
        
        print(f"æ­£åœ¨å¤„ç†éŸ³é¢‘æ–‡ä»¶: {os.path.basename(audio_path)}")
        
        try:
            result = self.speech_processor.transcribe_and_summarize(
                audio_path, language, summary_type
            )
            filepath = self.speech_processor.save_results(result)
            
            duration = result['metadata']['duration']
            print(f"âœ… éŸ³é¢‘å¤„ç†å®Œæˆ!")
            print(f"ğŸ“„ è½¬å½•æ–‡ä»¶ä¿å­˜è‡³: {filepath}")
            print(f"â±ï¸ éŸ³é¢‘æ—¶é•¿: {duration:.1f} ç§’")
            print(f"ğŸ”¤ è¯†åˆ«è¯­è¨€: {result['transcription']['language']}")
            
            return result
        except Exception as e:
            print(f"âŒ éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}")
            return None
    
    def generate_video(self, text_prompt: str, video_style: str = "æ•™è‚²", duration: int = 30, output_type: str = "text_video"):
        if not VIDEO_GENERATION_AVAILABLE or not self.video_generator:
            print("âŒ è§†é¢‘ç”ŸæˆåŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…è§†é¢‘ç”Ÿæˆä¾èµ–: pip install -r requirements-video.txt")
            return None
            
        print(f"æ­£åœ¨ç”Ÿæˆè§†é¢‘: {text_prompt[:30]}...")
        
        try:
            result = self.video_generator.generate_video_from_text(
                text_prompt, video_style, duration, output_type
            )
            
            file_size = result['metadata']['file_size'] / (1024 * 1024)  # MB
            print(f"âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ!")
            print(f"ğŸ¥ è§†é¢‘ä¿å­˜è‡³: {result['video_path']}")
            print(f"â±ï¸ è§†é¢‘æ—¶é•¿: {duration} ç§’")
            print(f"ğŸ’¾ æ–‡ä»¶å¤§å°: {file_size:.1f} MB")
            
            self.video_generator.cleanup_temp_files()
            return result
        except Exception as e:
            print(f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    def optimize_prompt(self, original_prompt: str, optimization_goal: str = "å…¨é¢ä¼˜åŒ–", target_domain: str = "é€šç”¨"):
        print(f"æ­£åœ¨ä¼˜åŒ–æç¤ºè¯...")
        
        try:
            analysis = self.prompt_optimizer.analyze_prompt(original_prompt)
            optimization = self.prompt_optimizer.optimize_prompt(original_prompt, optimization_goal, target_domain)
            
            print(f"âœ… æç¤ºè¯ä¼˜åŒ–å®Œæˆ!")
            print(f"ğŸ“Š åŸå§‹æç¤ºè¯é•¿åº¦: {len(original_prompt)} å­—ç¬¦")
            
            if 'scores' in analysis:
                avg_score = sum(analysis['scores'].values()) / len(analysis['scores'])
                print(f"ğŸ“ˆ åˆ†æè¯„åˆ†: {avg_score:.1f}/10")
            
            return {
                "analysis": analysis,
                "optimization": optimization
            }
        except Exception as e:
            print(f"âŒ æç¤ºè¯ä¼˜åŒ–å¤±è´¥: {str(e)}")
            return None
    
    def generate_image(self, prompt: str, style: str = "å†™å®", width: int = 512, height: int = 512, num_images: int = 1):
        if not IMAGE_GENERATION_AVAILABLE or not self.text_to_image:
            print("âŒ å›¾åƒç”ŸæˆåŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…å›¾åƒç”Ÿæˆä¾èµ–: pip install -r requirements-image.txt")
            return None
        
        print(f"æ­£åœ¨ç”Ÿæˆå›¾åƒ: {prompt[:30]}...")
        
        try:
            result = self.text_to_image.generate_image(
                prompt=prompt,
                style=style,
                width=width,
                height=height,
                num_images=num_images
            )
            
            if result:
                print(f"âœ… å›¾åƒç”ŸæˆæˆåŠŸ!")
                print(f"ğŸ–¼ï¸ ç”Ÿæˆæ•°é‡: {len(result['images'])}")
                print(f"ğŸ“ å°ºå¯¸: {result['metadata']['width']}x{result['metadata']['height']}")
                print(f"ğŸ­ é£æ ¼: {result['metadata']['style']}")
                print(f"ğŸ“ ä¿å­˜è·¯å¾„: {result['saved_paths']}")
            
            return result
        except Exception as e:
            print(f"âŒ å›¾åƒç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    def create_slideshow_video(self, image_paths: list, duration_per_image: float = 3.0):
        if not (IMAGE_GENERATION_AVAILABLE and VIDEO_GENERATION_AVAILABLE):
            print("âŒ å›¾ç‰‡è½¬è§†é¢‘åŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…ä¾èµ–: pip install -r requirements-image.txt requirements-video.txt")
            return None
        
        if not self.image_to_video:
            print("âŒ å›¾ç‰‡è½¬è§†é¢‘æ¨¡å—æœªåˆå§‹åŒ–")
            return None
        
        print(f"æ­£åœ¨åˆ›å»ºå¹»ç¯ç‰‡è§†é¢‘ï¼Œå›¾ç‰‡æ•°é‡: {len(image_paths)}")
        
        try:
            result = self.image_to_video.create_slideshow_video(
                image_paths=image_paths,
                duration_per_image=duration_per_image
            )
            
            if result:
                file_size = result['metadata']['file_size'] / (1024 * 1024)
                print(f"âœ… å¹»ç¯ç‰‡è§†é¢‘åˆ›å»ºæˆåŠŸ!")
                print(f"ğŸ¥ è§†é¢‘ä¿å­˜è‡³: {result['video_path']}")
                print(f"â±ï¸ æ€»æ—¶é•¿: {result['metadata']['total_duration']}ç§’")
                print(f"ğŸ’¾ æ–‡ä»¶å¤§å°: {file_size:.1f} MB")
            
            return result
        except Exception as e:
            print(f"âŒ è§†é¢‘åˆ›å»ºå¤±è´¥: {str(e)}")
            return None
    
    def edit_image(self, image_path: str, edit_prompt: str):
        if not IMAGE_GENERATION_AVAILABLE or not self.image_editor:
            print("âŒ å›¾åƒç¼–è¾‘åŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…å›¾åƒç¼–è¾‘ä¾èµ–: pip install -r requirements-image.txt")
            return None
        
        if not os.path.exists(image_path):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return None
        
        print(f"æ­£åœ¨ç¼–è¾‘å›¾åƒ: {os.path.basename(image_path)}")
        
        try:
            result = self.image_editor.edit_image(
                image=image_path,
                edit_prompt=edit_prompt
            )
            
            if result:
                print(f"âœ… å›¾åƒç¼–è¾‘æˆåŠŸ!")
                print(f"ğŸ–¼ï¸ åŸå›¾: {image_path}")
                print(f"ğŸ“ ç¼–è¾‘åä¿å­˜è‡³: {result['output_path']}")
                print(f"ğŸ¯ ç¼–è¾‘æŒ‡ä»¤: {result['metadata']['edit_prompt']}")
            
            return result
        except Exception as e:
            print(f"âŒ å›¾åƒç¼–è¾‘å¤±è´¥: {str(e)}")
            return None
    
    def generate_avatar(self, avatar_type: str, description: str = ""):
        """ç”Ÿæˆè™šæ‹Ÿå½¢è±¡"""
        if not IMAGE_GENERATION_AVAILABLE or not self.image_editor:
            print("âŒ å›¾åƒç¼–è¾‘åŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…å›¾åƒç¼–è¾‘ä¾èµ–: pip install -r requirements-image.txt")
            return None
        
        print(f"æ­£åœ¨ç”Ÿæˆè™šæ‹Ÿå½¢è±¡: {avatar_type}")
        
        try:
            result = self.image_editor.generate_avatar(
                avatar_type=avatar_type,
                description=description
            )
            
            if result:
                print(f"âœ… è™šæ‹Ÿå½¢è±¡ç”ŸæˆæˆåŠŸ!")
                print(f"ğŸ“ ä¿å­˜è‡³: {result['output_path']}")
                print(f"ğŸ‘¤ å½¢è±¡ç±»å‹: {avatar_type}")
                if description:
                    print(f"ğŸ“ æè¿°: {description}")
            
            return result
        except Exception as e:
            print(f"âŒ è™šæ‹Ÿå½¢è±¡ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    def ai_remove_object(self, image_path: str, remove_type: str, target_object: str = ""):
        """AIæ¶ˆé™¤åŠŸèƒ½"""
        if not IMAGE_GENERATION_AVAILABLE or not self.image_editor:
            print("âŒ å›¾åƒç¼–è¾‘åŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…å›¾åƒç¼–è¾‘ä¾èµ–: pip install -r requirements-image.txt")
            return None
        
        if not os.path.exists(image_path):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return None
        
        print(f"æ­£åœ¨æ‰§è¡ŒAIæ¶ˆé™¤: {remove_type}")
        if target_object:
            print(f"ç›®æ ‡å¯¹è±¡: {target_object}")
        
        try:
            result = self.image_editor.ai_remove(
                image=image_path,
                remove_type=remove_type,
                target_object=target_object
            )
            
            if result:
                print(f"âœ… AIæ¶ˆé™¤æˆåŠŸ!")
                print(f"ğŸ–¼ï¸ åŸå›¾: {image_path}")
                print(f"ğŸ“ ä¿å­˜è‡³: {result['output_path']}")
            
            return result
        except Exception as e:
            print(f"âŒ AIæ¶ˆé™¤å¤±è´¥: {str(e)}")
            return None
    
    def ai_redraw_area(self, image_path: str, redraw_type: str, description: str):
        """AIé‡ç»˜åŠŸèƒ½"""
        if not IMAGE_GENERATION_AVAILABLE or not self.image_editor:
            print("âŒ å›¾åƒç¼–è¾‘åŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…å›¾åƒç¼–è¾‘ä¾èµ–: pip install -r requirements-image.txt")
            return None
        
        if not os.path.exists(image_path):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return None
        
        print(f"æ­£åœ¨æ‰§è¡ŒAIé‡ç»˜: {redraw_type}")
        print(f"é‡ç»˜æè¿°: {description}")
        
        try:
            result = self.image_editor.ai_redraw(
                image=image_path,
                redraw_type=redraw_type,
                description=description
            )
            
            if result:
                print(f"âœ… AIé‡ç»˜æˆåŠŸ!")
                print(f"ğŸ–¼ï¸ åŸå›¾: {image_path}")
                print(f"ğŸ“ ä¿å­˜è‡³: {result['output_path']}")
            
            return result
        except Exception as e:
            print(f"âŒ AIé‡ç»˜å¤±è´¥: {str(e)}")
            return None
    
    def create_virtual_scene(self, image_path: str, scene_type: str, scene_elements: str = ""):
        """è™šæ‹Ÿåœºæ™¯ç”Ÿæˆ"""
        if not IMAGE_GENERATION_AVAILABLE or not self.image_editor:
            print("âŒ å›¾åƒç¼–è¾‘åŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…å›¾åƒç¼–è¾‘ä¾èµ–: pip install -r requirements-image.txt")
            return None
        
        if not os.path.exists(image_path):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return None
        
        print(f"æ­£åœ¨ç”Ÿæˆè™šæ‹Ÿåœºæ™¯: {scene_type}")
        if scene_elements:
            print(f"åœºæ™¯å…ƒç´ : {scene_elements}")
        
        try:
            result = self.image_editor.virtual_scene(
                image=image_path,
                scene_type=scene_type,
                scene_elements=scene_elements
            )
            
            if result:
                print(f"âœ… è™šæ‹Ÿåœºæ™¯ç”ŸæˆæˆåŠŸ!")
                print(f"ğŸ–¼ï¸ åŸå›¾: {image_path}")
                print(f"ğŸ“ ä¿å­˜è‡³: {result['output_path']}")
            
            return result
        except Exception as e:
            print(f"âŒ è™šæ‹Ÿåœºæ™¯ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    def simulate_outfit(self, image_path: str, outfit_type: str, outfit_details: str):
        """ç©¿æ­æ¨¡æ‹Ÿ"""
        if not IMAGE_GENERATION_AVAILABLE or not self.image_editor:
            print("âŒ å›¾åƒç¼–è¾‘åŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…å›¾åƒç¼–è¾‘ä¾èµ–: pip install -r requirements-image.txt")
            return None
        
        if not os.path.exists(image_path):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return None
        
        print(f"æ­£åœ¨æ¨¡æ‹Ÿç©¿æ­: {outfit_type}")
        print(f"ç©¿æ­è¯¦æƒ…: {outfit_details}")
        
        try:
            result = self.image_editor.outfit_simulation(
                image=image_path,
                outfit_type=outfit_type,
                outfit_details=outfit_details
            )
            
            if result:
                print(f"âœ… ç©¿æ­æ¨¡æ‹ŸæˆåŠŸ!")
                print(f"ğŸ–¼ï¸ åŸå›¾: {image_path}")
                print(f"ğŸ“ ä¿å­˜è‡³: {result['output_path']}")
            
            return result
        except Exception as e:
            print(f"âŒ ç©¿æ­æ¨¡æ‹Ÿå¤±è´¥: {str(e)}")
            return None
    
    def design_text_poster(self, image_path: str, design_type: str, content: str, style: str = ""):
        """æ–‡å­—è®¾è®¡å’Œæµ·æŠ¥ç¼–è¾‘"""
        if not IMAGE_GENERATION_AVAILABLE or not self.image_editor:
            print("âŒ å›¾åƒç¼–è¾‘åŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…å›¾åƒç¼–è¾‘ä¾èµ–: pip install -r requirements-image.txt")
            return None
        
        if not os.path.exists(image_path):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return None
        
        print(f"æ­£åœ¨è®¾è®¡{design_type}: {content}")
        if style:
            print(f"è®¾è®¡é£æ ¼: {style}")
        
        try:
            if design_type in ["æ–‡å­—è®¾è®¡", "è‰ºæœ¯å­—ä½“", "æ ‡é¢˜è®¾è®¡", "logoè®¾è®¡"]:
                result = self.image_editor.text_design(
                    image=image_path,
                    text_type=design_type,
                    text_content=content,
                    font_style=style or "modern"
                )
            else:
                result = self.image_editor.poster_design(
                    image=image_path,
                    poster_type=design_type,
                    theme=style or content
                )
            
            if result:
                print(f"âœ… {design_type}è®¾è®¡æˆåŠŸ!")
                print(f"ğŸ–¼ï¸ åŸå›¾: {image_path}")
                print(f"ğŸ“ ä¿å­˜è‡³: {result['output_path']}")
            
            return result
        except Exception as e:
            print(f"âŒ {design_type}è®¾è®¡å¤±è´¥: {str(e)}")
            return None
    
    def interactive_mode(self):
        print("ğŸ¤– æ¬¢è¿ä½¿ç”¨AIå†…å®¹åˆ›ä½œç³»ç»Ÿ!")
        print("æ”¯æŒçš„åŠŸèƒ½:")
        print("1. æ–‡ç« å†™ä½œ")
        print("2. å°è¯´åˆ›ä½œ") 
        print("3. è¯­éŸ³è¯†åˆ«")
        if VIDEO_GENERATION_AVAILABLE:
            print("4. è§†é¢‘ç”Ÿæˆ")
        else:
            print("4. è§†é¢‘ç”Ÿæˆ (ä¸å¯ç”¨ - éœ€è¦å®‰è£…é¢å¤–ä¾èµ–)")
        print("5. æç¤ºè¯ä¼˜åŒ–")
        if IMAGE_GENERATION_AVAILABLE:
            print("6. æ–‡æœ¬ç”Ÿæˆå›¾ç‰‡")
            print("7. å›¾åƒç¼–è¾‘")
            print("8. å›¾ç‰‡è½¬è§†é¢‘")
        else:
            print("6. æ–‡æœ¬ç”Ÿæˆå›¾ç‰‡ (ä¸å¯ç”¨ - éœ€è¦å®‰è£…é¢å¤–ä¾èµ–)")
            print("7. å›¾åƒç¼–è¾‘ (ä¸å¯ç”¨ - éœ€è¦å®‰è£…é¢å¤–ä¾èµ–)")
            print("8. å›¾ç‰‡è½¬è§†é¢‘ (ä¸å¯ç”¨ - éœ€è¦å®‰è£…é¢å¤–ä¾èµ–)")
        print("0. é€€å‡º")
        print("-" * 50)
        
        while True:
            try:
                choice = input("\nè¯·é€‰æ‹©åŠŸèƒ½ (0-8): ").strip()
                
                if choice == "0":
                    print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨AIå†…å®¹åˆ›ä½œç³»ç»Ÿ!")
                    break
                elif choice == "1":
                    self._interactive_article()
                elif choice == "2":
                    self._interactive_novel()
                elif choice == "3":
                    self._interactive_audio()
                elif choice == "4":
                    self._interactive_video()
                elif choice == "5":
                    self._interactive_prompt()
                elif choice == "6":
                    self._interactive_image_generation()
                elif choice == "7":
                    self._interactive_image_editing()
                elif choice == "8":
                    self._interactive_image_to_video()
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥0-8ä¹‹é—´çš„æ•°å­—")
            
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
    
    def _interactive_article(self):
        topic = input("è¯·è¾“å…¥æ–‡ç« ä¸»é¢˜: ").strip()
        if not topic:
            print("âŒ ä¸»é¢˜ä¸èƒ½ä¸ºç©º")
            return
        
        print("æ–‡ç« é£æ ¼é€‰é¡¹: informative, narrative, persuasive, technical, casual")
        style = input("è¯·é€‰æ‹©æ–‡ç« é£æ ¼ (é»˜è®¤: informative): ").strip() or "informative"
        
        print("æ–‡ç« é•¿åº¦é€‰é¡¹: short, medium, long")
        length = input("è¯·é€‰æ‹©æ–‡ç« é•¿åº¦ (é»˜è®¤: medium): ").strip() or "medium"
        
        self.generate_article(topic, style, length)
    
    def _interactive_novel(self):
        print("å°è¯´åˆ›ä½œé€‰é¡¹:")
        print("1. ç”Ÿæˆç« èŠ‚")
        print("2. ç”Ÿæˆå¤§çº²")
        
        choice = input("è¯·é€‰æ‹© (1-2): ").strip()
        
        if choice == "1":
            plot = input("è¯·è¾“å…¥ç« èŠ‚å‰§æƒ…: ").strip()
            if not plot:
                print("âŒ å‰§æƒ…ä¸èƒ½ä¸ºç©º")
                return
            
            characters = input("è¯·è¾“å…¥ä¸»è¦äººç‰© (å¯é€‰): ").strip()
            setting = input("è¯·è¾“å…¥èƒŒæ™¯è®¾å®š (å¯é€‰): ").strip()
            
            try:
                chapter_num = int(input("è¯·è¾“å…¥ç« èŠ‚ç¼–å· (é»˜è®¤: 1): ").strip() or "1")
            except ValueError:
                chapter_num = 1
            
            self.generate_novel_chapter(plot, characters, setting, chapter_num)
        
        elif choice == "2":
            theme = input("è¯·è¾“å…¥å°è¯´ä¸»é¢˜: ").strip()
            if not theme:
                print("âŒ ä¸»é¢˜ä¸èƒ½ä¸ºç©º")
                return
            
            genre = input("è¯·è¾“å…¥å°è¯´ç±»å‹ (é»˜è®¤: ç°ä»£): ").strip() or "ç°ä»£"
            length = input("è¯·è¾“å…¥å°è¯´é•¿åº¦ (é»˜è®¤: ä¸­ç¯‡): ").strip() or "ä¸­ç¯‡"
            
            self.generate_story_outline(theme, genre, length)
    
    def _interactive_audio(self):
        audio_path = input("è¯·è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„: ").strip()
        if not audio_path:
            print("âŒ æ–‡ä»¶è·¯å¾„ä¸èƒ½ä¸ºç©º")
            return
        
        print("è¯­è¨€é€‰é¡¹: zh (ä¸­æ–‡), en (è‹±æ–‡)")
        language = input("è¯·é€‰æ‹©è¯­è¨€ (é»˜è®¤: zh): ").strip() or "zh"
        
        print("æ‘˜è¦ç±»å‹: ç®€è¦, è¯¦ç»†, è¦ç‚¹, ä¼šè®®çºªè¦")
        summary_type = input("è¯·é€‰æ‹©æ‘˜è¦ç±»å‹ (é»˜è®¤: è¯¦ç»†): ").strip() or "è¯¦ç»†"
        
        self.process_audio(audio_path, language, summary_type)
    
    def _interactive_video(self):
        text_prompt = input("è¯·è¾“å…¥è§†é¢‘å†…å®¹æè¿°: ").strip()
        if not text_prompt:
            print("âŒ å†…å®¹æè¿°ä¸èƒ½ä¸ºç©º")
            return
        
        print("è§†é¢‘é£æ ¼: æ•™è‚², è¥é”€, æ•…äº‹, è§£è¯´, ç¤¾äº¤")
        video_style = input("è¯·é€‰æ‹©è§†é¢‘é£æ ¼ (é»˜è®¤: æ•™è‚²): ").strip() or "æ•™è‚²"
        
        try:
            duration = int(input("è¯·è¾“å…¥è§†é¢‘æ—¶é•¿/ç§’ (é»˜è®¤: 30): ").strip() or "30")
        except ValueError:
            duration = 30
        
        print("è¾“å‡ºç±»å‹: text_video (æ–‡å­—è§†é¢‘), slideshow (å¹»ç¯ç‰‡)")
        output_type = input("è¯·é€‰æ‹©è¾“å‡ºç±»å‹ (é»˜è®¤: text_video): ").strip() or "text_video"
        
        self.generate_video(text_prompt, video_style, duration, output_type)
    
    def _interactive_prompt(self):
        original_prompt = input("è¯·è¾“å…¥éœ€è¦ä¼˜åŒ–çš„æç¤ºè¯: ").strip()
        if not original_prompt:
            print("âŒ æç¤ºè¯ä¸èƒ½ä¸ºç©º")
            return
        
        print("ä¼˜åŒ–ç›®æ ‡: å…¨é¢ä¼˜åŒ–, æé«˜æ¸…æ™°åº¦, å¢å¼ºå…·ä½“æ€§, æ”¹è¿›ç»“æ„, æå‡å¯æ“ä½œæ€§")
        goal = input("è¯·é€‰æ‹©ä¼˜åŒ–ç›®æ ‡ (é»˜è®¤: å…¨é¢ä¼˜åŒ–): ").strip() or "å…¨é¢ä¼˜åŒ–"
        
        print("åº”ç”¨é¢†åŸŸ: é€šç”¨, å†™ä½œ, åˆ†æ, åˆ›æ„, æŠ€æœ¯, æ•™è‚², è¥é”€")
        domain = input("è¯·é€‰æ‹©åº”ç”¨é¢†åŸŸ (é»˜è®¤: é€šç”¨): ").strip() or "é€šç”¨"
        
        result = self.optimize_prompt(original_prompt, goal, domain)
        
        if result:
            print("\n" + "="*50)
            print("ğŸ“Š åˆ†æç»“æœ:")
            print(result['analysis'].get('analysis', 'åˆ†æä¿¡æ¯ä¸å¯ç”¨'))
            print("\n" + "="*50)
            print("âœ¨ ä¼˜åŒ–ç»“æœ:")
            print(result['optimization'].get('result', 'ä¼˜åŒ–ä¿¡æ¯ä¸å¯ç”¨'))
    
    def _interactive_image_generation(self):
        if not IMAGE_GENERATION_AVAILABLE:
            print("âŒ å›¾åƒç”ŸæˆåŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…å›¾åƒç”Ÿæˆä¾èµ–: pip install -r requirements-image.txt")
            return
        
        prompt = input("è¯·è¾“å…¥å›¾ç‰‡æè¿°: ").strip()
        if not prompt:
            print("âŒ å›¾ç‰‡æè¿°ä¸èƒ½ä¸ºç©º")
            return
        
        print("è‰ºæœ¯é£æ ¼: å†™å®, åŠ¨æ¼«, æ²¹ç”», æ°´å½©, ç´ æ, å¡é€š, ç§‘å¹», æ¢¦å¹»")
        style = input("è¯·é€‰æ‹©è‰ºæœ¯é£æ ¼ (é»˜è®¤: å†™å®): ").strip() or "å†™å®"
        
        try:
            width = int(input("è¯·è¾“å…¥å›¾ç‰‡å®½åº¦ (é»˜è®¤: 512): ").strip() or "512")
            height = int(input("è¯·è¾“å…¥å›¾ç‰‡é«˜åº¦ (é»˜è®¤: 512): ").strip() or "512")
            num_images = int(input("è¯·è¾“å…¥ç”Ÿæˆæ•°é‡ (é»˜è®¤: 1): ").strip() or "1")
        except ValueError:
            width, height, num_images = 512, 512, 1
        
        self.generate_image(prompt, style, width, height, num_images)
    
    def _interactive_image_to_video(self):
        if not (IMAGE_GENERATION_AVAILABLE and VIDEO_GENERATION_AVAILABLE):
            print("âŒ å›¾ç‰‡è½¬è§†é¢‘åŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…ä¾èµ–: pip install -r requirements-image.txt requirements-video.txt")
            return
        
        print("å›¾ç‰‡è½¬è§†é¢‘åŠŸèƒ½:")
        print("è¯·è¾“å…¥å›¾ç‰‡æ–‡ä»¶è·¯å¾„ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œè¾“å…¥ç©ºè¡Œç»“æŸ:")
        
        image_paths = []
        while True:
            path = input("å›¾ç‰‡è·¯å¾„: ").strip()
            if not path:
                break
            if os.path.exists(path):
                image_paths.append(path)
                print(f"âœ… æ·»åŠ å›¾ç‰‡: {os.path.basename(path)}")
            else:
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        
        if not image_paths:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶")
            return
        
        try:
            duration = float(input("æ¯å¼ å›¾ç‰‡æ˜¾ç¤ºæ—¶é•¿/ç§’ (é»˜è®¤: 3.0): ").strip() or "3.0")
        except ValueError:
            duration = 3.0
        
        self.create_slideshow_video(image_paths, duration)
    
    def _interactive_image_editing(self):
        if not IMAGE_GENERATION_AVAILABLE:
            print("âŒ å›¾åƒç¼–è¾‘åŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…å›¾åƒç¼–è¾‘ä¾èµ–: pip install -r requirements-image.txt")
            return
        
        image_path = input("è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„: ").strip()
        if not image_path:
            print("âŒ å›¾ç‰‡è·¯å¾„ä¸èƒ½ä¸ºç©º")
            return
        
        if not os.path.exists(image_path):
            print(f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return
        
        print("\nç¼–è¾‘æ¨¡å¼:")
        print("1. è‡ªç”±ç¼–è¾‘")
        print("2. è§†è§’è½¬æ¢")
        print("3. é£æ ¼å˜æ¢")
        print("4. ç¯å¢ƒå˜æ¢")
        print("5. å¯¹è±¡å˜æ¢")
        
        mode = input("è¯·é€‰æ‹©ç¼–è¾‘æ¨¡å¼ (1-5): ").strip()
        
        if mode == "1":
            edit_prompt = input("è¯·è¾“å…¥ç¼–è¾‘æŒ‡ä»¤: ").strip()
            if edit_prompt:
                self.edit_image(image_path, edit_prompt)
            else:
                print("âŒ ç¼–è¾‘æŒ‡ä»¤ä¸èƒ½ä¸ºç©º")
        
        elif mode == "2":
            print("è§†è§’é€‰é¡¹: ä»æ­£é¢çœ‹, ä»ä¾§é¢çœ‹, ä»èƒŒé¢çœ‹, ä»ä¸Šå¾€ä¸‹çœ‹, ä»ä¸‹å¾€ä¸Šçœ‹, ä¿¯è§†å›¾, ä»°è§†å›¾")
            view = input("è¯·é€‰æ‹©ç›®æ ‡è§†è§’: ").strip()
            if view:
                try:
                    result = self.image_editor.perspective_transform(image_path, view)
                    if result:
                        print(f"âœ… è§†è§’è½¬æ¢æˆåŠŸ! ä¿å­˜è‡³: {result['output_path']}")
                except Exception as e:
                    print(f"âŒ è§†è§’è½¬æ¢å¤±è´¥: {e}")
            else:
                print("âŒ ç›®æ ‡è§†è§’ä¸èƒ½ä¸ºç©º")
        
        elif mode == "3":
            print("é£æ ¼é€‰é¡¹: æ²¹ç”»é£æ ¼, æ°´å½©é£æ ¼, ç´ æé£æ ¼, åŠ¨æ¼«é£æ ¼, ç…§ç‰‡é£æ ¼, å°è±¡æ´¾, æŠ½è±¡è‰ºæœ¯")
            style = input("è¯·é€‰æ‹©ç›®æ ‡é£æ ¼: ").strip()
            if style:
                try:
                    result = self.image_editor.style_transform(image_path, style)
                    if result:
                        print(f"âœ… é£æ ¼å˜æ¢æˆåŠŸ! ä¿å­˜è‡³: {result['output_path']}")
                except Exception as e:
                    print(f"âŒ é£æ ¼å˜æ¢å¤±è´¥: {e}")
            else:
                print("âŒ ç›®æ ‡é£æ ¼ä¸èƒ½ä¸ºç©º")
        
        elif mode == "4":
            print("ç¯å¢ƒé€‰é¡¹: ç™½å¤©è½¬å¤œæ™š, å¤œæ™šè½¬ç™½å¤©, æ™´å¤©è½¬é›¨å¤©, å®¤å†…è½¬å®¤å¤–, ç°ä»£è½¬å¤ä»£, åŸå¸‚è½¬ä¹¡æ‘, æ˜¥å¤©è½¬ç§‹å¤©")
            env = input("è¯·é€‰æ‹©ç¯å¢ƒå˜æ¢: ").strip()
            if env:
                try:
                    result = self.image_editor.environment_transform(image_path, env)
                    if result:
                        print(f"âœ… ç¯å¢ƒå˜æ¢æˆåŠŸ! ä¿å­˜è‡³: {result['output_path']}")
                except Exception as e:
                    print(f"âŒ ç¯å¢ƒå˜æ¢å¤±è´¥: {e}")
            else:
                print("âŒ ç¯å¢ƒå˜æ¢ä¸èƒ½ä¸ºç©º")
        
        elif mode == "5":
            print("å˜æ¢ç±»å‹: æ”¹å˜é¢œè‰², æ”¹å˜æè´¨, æ”¹å˜å¤§å°, æ·»åŠ è£…é¥°, æ”¹å˜è¡¨æƒ…, æ”¹å˜å§¿æ€, æ”¹å˜æœè£…")
            transform_type = input("è¯·é€‰æ‹©å˜æ¢ç±»å‹: ").strip()
            transform_value = input("è¯·è¾“å…¥å˜æ¢ç›®æ ‡å€¼: ").strip()
            if transform_type and transform_value:
                try:
                    result = self.image_editor.object_transform(image_path, transform_type, transform_value)
                    if result:
                        print(f"âœ… å¯¹è±¡å˜æ¢æˆåŠŸ! ä¿å­˜è‡³: {result['output_path']}")
                except Exception as e:
                    print(f"âŒ å¯¹è±¡å˜æ¢å¤±è´¥: {e}")
            else:
                print("âŒ å˜æ¢ç±»å‹å’Œç›®æ ‡å€¼éƒ½ä¸èƒ½ä¸ºç©º")
        
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")

def main():
    parser = argparse.ArgumentParser(description="AIå†…å®¹åˆ›ä½œç³»ç»Ÿ")
    parser.add_argument("--interactive", "-i", action="store_true", help="äº¤äº’æ¨¡å¼")
    parser.add_argument("--article", help="ç”Ÿæˆæ–‡ç« ï¼ŒæŒ‡å®šä¸»é¢˜")
    parser.add_argument("--audio", help="å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼ŒæŒ‡å®šæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--video", help="ç”Ÿæˆè§†é¢‘ï¼ŒæŒ‡å®šå†…å®¹æè¿°")
    parser.add_argument("--optimize-prompt", help="ä¼˜åŒ–æç¤ºè¯")
    parser.add_argument("--generate-image", help="ç”Ÿæˆå›¾ç‰‡ï¼ŒæŒ‡å®šæè¿°")
    parser.add_argument("--edit-image", help="ç¼–è¾‘å›¾ç‰‡ï¼Œæ ¼å¼ï¼šå›¾ç‰‡è·¯å¾„,ç¼–è¾‘æŒ‡ä»¤")
    parser.add_argument("--image-to-video", help="å›¾ç‰‡è½¬è§†é¢‘ï¼ŒæŒ‡å®šå›¾ç‰‡ç›®å½•")
    parser.add_argument("--generate-avatar", help="ç”Ÿæˆè™šæ‹Ÿå½¢è±¡ï¼Œæ ¼å¼ï¼šå½¢è±¡ç±»å‹,æè¿°")
    parser.add_argument("--ai-remove", help="AIæ¶ˆé™¤ï¼Œæ ¼å¼ï¼šå›¾ç‰‡è·¯å¾„,æ¶ˆé™¤ç±»å‹,ç›®æ ‡å¯¹è±¡")
    parser.add_argument("--ai-redraw", help="AIé‡ç»˜ï¼Œæ ¼å¼ï¼šå›¾ç‰‡è·¯å¾„,é‡ç»˜ç±»å‹,æè¿°")
    parser.add_argument("--virtual-scene", help="è™šæ‹Ÿåœºæ™¯ï¼Œæ ¼å¼ï¼šå›¾ç‰‡è·¯å¾„,åœºæ™¯ç±»å‹,åœºæ™¯å…ƒç´ ")
    parser.add_argument("--outfit-sim", help="ç©¿æ­æ¨¡æ‹Ÿï¼Œæ ¼å¼ï¼šå›¾ç‰‡è·¯å¾„,ç©¿æ­ç±»å‹,ç©¿æ­è¯¦æƒ…")
    parser.add_argument("--text-poster", help="æ–‡å­—æµ·æŠ¥ï¼Œæ ¼å¼ï¼šå›¾ç‰‡è·¯å¾„,è®¾è®¡ç±»å‹,å†…å®¹,é£æ ¼")
    
    args = parser.parse_args()
    
    system = AI2CSystem()
    
    if args.interactive or len(sys.argv) == 1:
        system.interactive_mode()
    elif args.article:
        system.generate_article(args.article)
    elif args.audio:
        system.process_audio(args.audio)
    elif args.video:
        system.generate_video(args.video)
    elif args.optimize_prompt:
        system.optimize_prompt(args.optimize_prompt)
    elif args.generate_image:
        system.generate_image(args.generate_image)
    elif args.edit_image:
        if "," in args.edit_image:
            image_path, edit_prompt = args.edit_image.split(",", 1)
            system.edit_image(image_path.strip(), edit_prompt.strip())
        else:
            print("âŒ è¯·ä½¿ç”¨æ ¼å¼: --edit-image 'å›¾ç‰‡è·¯å¾„,ç¼–è¾‘æŒ‡ä»¤'")
    elif args.image_to_video:
        import glob
        image_paths = glob.glob(os.path.join(args.image_to_video, "*.{jpg,jpeg,png,webp}"))
        if image_paths:
            system.create_slideshow_video(image_paths)
        else:
            print(f"âŒ åœ¨ç›®å½• {args.image_to_video} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
    elif args.generate_avatar:
        if "," in args.generate_avatar:
            avatar_type, description = args.generate_avatar.split(",", 1)
            system.generate_avatar(avatar_type.strip(), description.strip())
        else:
            system.generate_avatar(args.generate_avatar.strip())
    elif args.ai_remove:
        parts = args.ai_remove.split(",")
        if len(parts) >= 2:
            image_path = parts[0].strip()
            remove_type = parts[1].strip()
            target_object = parts[2].strip() if len(parts) > 2 else ""
            system.ai_remove_object(image_path, remove_type, target_object)
        else:
            print("âŒ è¯·ä½¿ç”¨æ ¼å¼: --ai-remove 'å›¾ç‰‡è·¯å¾„,æ¶ˆé™¤ç±»å‹,ç›®æ ‡å¯¹è±¡'")
    elif args.ai_redraw:
        parts = args.ai_redraw.split(",")
        if len(parts) >= 3:
            image_path = parts[0].strip()
            redraw_type = parts[1].strip()
            description = parts[2].strip()
            system.ai_redraw_area(image_path, redraw_type, description)
        else:
            print("âŒ è¯·ä½¿ç”¨æ ¼å¼: --ai-redraw 'å›¾ç‰‡è·¯å¾„,é‡ç»˜ç±»å‹,æè¿°'")
    elif args.virtual_scene:
        parts = args.virtual_scene.split(",")
        if len(parts) >= 2:
            image_path = parts[0].strip()
            scene_type = parts[1].strip()
            scene_elements = parts[2].strip() if len(parts) > 2 else ""
            system.create_virtual_scene(image_path, scene_type, scene_elements)
        else:
            print("âŒ è¯·ä½¿ç”¨æ ¼å¼: --virtual-scene 'å›¾ç‰‡è·¯å¾„,åœºæ™¯ç±»å‹,åœºæ™¯å…ƒç´ '")
    elif args.outfit_sim:
        parts = args.outfit_sim.split(",")
        if len(parts) >= 3:
            image_path = parts[0].strip()
            outfit_type = parts[1].strip()
            outfit_details = parts[2].strip()
            system.simulate_outfit(image_path, outfit_type, outfit_details)
        else:
            print("âŒ è¯·ä½¿ç”¨æ ¼å¼: --outfit-sim 'å›¾ç‰‡è·¯å¾„,ç©¿æ­ç±»å‹,ç©¿æ­è¯¦æƒ…'")
    elif args.text_poster:
        parts = args.text_poster.split(",")
        if len(parts) >= 3:
            image_path = parts[0].strip()
            design_type = parts[1].strip()
            content = parts[2].strip()
            style = parts[3].strip() if len(parts) > 3 else ""
            system.design_text_poster(image_path, design_type, content, style)
        else:
            print("âŒ è¯·ä½¿ç”¨æ ¼å¼: --text-poster 'å›¾ç‰‡è·¯å¾„,è®¾è®¡ç±»å‹,å†…å®¹,é£æ ¼'")
    else:
        parser.print_help()

if __name__ == "__main__":
    main()