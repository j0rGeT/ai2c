#!/usr/bin/env python3
"""
AIå†…å®¹åˆ›ä½œç³»ç»Ÿ - ä¸»ç¨‹åº
æ”¯æŒæ–‡ç« å†™ä½œã€è¯­éŸ³è¯†åˆ«ã€è§†é¢‘ç”Ÿæˆã€æç¤ºè¯ä¼˜åŒ–ç­‰åŠŸèƒ½
"""

import os
import sys
import argparse
import json
from datetime import datetime
from typing import Dict, Any

from src.content_generation.content_generator import ContentGenerator
from src.speech_recognition.speech_processor import SpeechProcessor
from src.prompt_optimization.prompt_optimizer import PromptOptimizer

# è§†é¢‘ç”Ÿæˆå™¨çš„å¯é€‰å¯¼å…¥
try:
    from src.video_generation.video_generator import VideoGenerator
    VIDEO_GENERATION_AVAILABLE = True
except ImportError:
    VIDEO_GENERATION_AVAILABLE = False
    VideoGenerator = None

# å›¾åƒç”Ÿæˆå™¨çš„å¯é€‰å¯¼å…¥
try:
    from src.image_generation.text_to_image import TextToImageGenerator
    from src.image_generation.image_to_video import ImageToVideoGenerator
    IMAGE_GENERATION_AVAILABLE = True
except ImportError:
    IMAGE_GENERATION_AVAILABLE = False
    TextToImageGenerator = None
    ImageToVideoGenerator = None

class AI2CSystem:
    def __init__(self):
        self.content_generator = ContentGenerator()
        self.speech_processor = SpeechProcessor()
        self.prompt_optimizer = PromptOptimizer()
        
        # è§†é¢‘ç”Ÿæˆå™¨çš„å¯é€‰åˆå§‹åŒ–
        if VIDEO_GENERATION_AVAILABLE:
            self.video_generator = VideoGenerator()
        else:
            self.video_generator = None
        
        # å›¾åƒç”Ÿæˆå™¨çš„å¯é€‰åˆå§‹åŒ–
        if IMAGE_GENERATION_AVAILABLE:
            self.text_to_image = TextToImageGenerator()
            self.image_to_video = ImageToVideoGenerator()
        else:
            self.text_to_image = None
            self.image_to_video = None
    
    def generate_article(self, topic: str, style: str = "informative", length: str = "medium", provider: str = None):
        print(f"æ­£åœ¨ç”Ÿæˆå…³äº'{topic}'çš„æ–‡ç« ...")
        
        try:
            result = self.content_generator.generate_article(topic, style, length, provider)
            filepath = self.content_generator.save_content(result)
            
            print(f"âœ… æ–‡ç« ç”ŸæˆæˆåŠŸ!")
            print(f"ğŸ“„ æ–‡ä»¶ä¿å­˜è‡³: {filepath}")
            print(f"ğŸ“Š å­—æ•°ç»Ÿè®¡: {result['metadata']['word_count']} å­—")
            
            return result
        except Exception as e:
            print(f"âŒ æ–‡ç« ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    def generate_novel_chapter(self, plot: str, characters: str = "", setting: str = "", chapter_number: int = 1, provider: str = None):
        print(f"æ­£åœ¨ç”Ÿæˆç¬¬{chapter_number}ç« å°è¯´...")
        
        try:
            result = self.content_generator.generate_novel_chapter(plot, characters, setting, chapter_number, provider)
            filepath = self.content_generator.save_content(result)
            
            print(f"âœ… å°è¯´ç« èŠ‚ç”ŸæˆæˆåŠŸ!")
            print(f"ğŸ“„ æ–‡ä»¶ä¿å­˜è‡³: {filepath}")
            print(f"ğŸ“Š å­—æ•°ç»Ÿè®¡: {result['metadata']['word_count']} å­—")
            
            return result
        except Exception as e:
            print(f"âŒ å°è¯´ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    def generate_story_outline(self, theme: str, genre: str = "ç°ä»£", length: str = "ä¸­ç¯‡", provider: str = None):
        print(f"æ­£åœ¨ç”Ÿæˆ'{theme}'å°è¯´å¤§çº²...")
        
        try:
            result = self.content_generator.generate_story_outline(theme, genre, length, provider)
            filepath = self.content_generator.save_content(result)
            
            print(f"âœ… å°è¯´å¤§çº²ç”ŸæˆæˆåŠŸ!")
            print(f"ğŸ“„ æ–‡ä»¶ä¿å­˜è‡³: {filepath}")
            
            return result
        except Exception as e:
            print(f"âŒ å¤§çº²ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    def process_audio(self, audio_path: str, language: str = "zh", summary_type: str = "è¯¦ç»†"):
        if not os.path.exists(audio_path):
            print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
            return None
        
        print(f"æ­£åœ¨å¤„ç†éŸ³é¢‘æ–‡ä»¶: {os.path.basename(audio_path)}")
        
        try:
            result = self.speech_processor.transcribe_and_summarize(
                audio_path, language, summary_type
            )
            filepath = self.speech_processor.save_results(result)
            
            duration = result['metadata']['duration']
            print(f"âœ… éŸ³é¢‘å¤„ç†å®Œæˆ!")
            print(f"ğŸ“„ è½¬å½•æ–‡ä»¶ä¿å­˜è‡³: {filepath}")
            print(f"â±ï¸ éŸ³é¢‘æ—¶é•¿: {duration:.1f} ç§’")
            print(f"ğŸ”¤ è¯†åˆ«è¯­è¨€: {result['transcription']['language']}")
            
            return result
        except Exception as e:
            print(f"âŒ éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}")
            return None
    
    def generate_video(self, text_prompt: str, video_style: str = "æ•™è‚²", duration: int = 30, output_type: str = "text_video"):
        if not VIDEO_GENERATION_AVAILABLE or not self.video_generator:
            print("âŒ è§†é¢‘ç”ŸæˆåŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…è§†é¢‘ç”Ÿæˆä¾èµ–: pip install -r requirements-video.txt")
            return None
            
        print(f"æ­£åœ¨ç”Ÿæˆè§†é¢‘: {text_prompt[:30]}...")
        
        try:
            result = self.video_generator.generate_video_from_text(
                text_prompt, video_style, duration, output_type
            )
            
            file_size = result['metadata']['file_size'] / (1024 * 1024)  # MB
            print(f"âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ!")
            print(f"ğŸ¥ è§†é¢‘ä¿å­˜è‡³: {result['video_path']}")
            print(f"â±ï¸ è§†é¢‘æ—¶é•¿: {duration} ç§’")
            print(f"ğŸ’¾ æ–‡ä»¶å¤§å°: {file_size:.1f} MB")
            
            self.video_generator.cleanup_temp_files()
            return result
        except Exception as e:
            print(f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    def optimize_prompt(self, original_prompt: str, optimization_goal: str = "å…¨é¢ä¼˜åŒ–", target_domain: str = "é€šç”¨"):
        print(f"æ­£åœ¨ä¼˜åŒ–æç¤ºè¯...")
        
        try:
            analysis = self.prompt_optimizer.analyze_prompt(original_prompt)
            optimization = self.prompt_optimizer.optimize_prompt(original_prompt, optimization_goal, target_domain)
            
            print(f"âœ… æç¤ºè¯ä¼˜åŒ–å®Œæˆ!")
            print(f"ğŸ“Š åŸå§‹æç¤ºè¯é•¿åº¦: {len(original_prompt)} å­—ç¬¦")
            
            if 'scores' in analysis:
                avg_score = sum(analysis['scores'].values()) / len(analysis['scores'])
                print(f"ğŸ“ˆ åˆ†æè¯„åˆ†: {avg_score:.1f}/10")
            
            return {
                "analysis": analysis,
                "optimization": optimization
            }
        except Exception as e:
            print(f"âŒ æç¤ºè¯ä¼˜åŒ–å¤±è´¥: {str(e)}")
            return None
    
    def generate_image(self, prompt: str, style: str = "å†™å®", width: int = 512, height: int = 512, num_images: int = 1):
        if not IMAGE_GENERATION_AVAILABLE or not self.text_to_image:
            print("âŒ å›¾åƒç”ŸæˆåŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…å›¾åƒç”Ÿæˆä¾èµ–: pip install -r requirements-image.txt")
            return None
        
        print(f"æ­£åœ¨ç”Ÿæˆå›¾åƒ: {prompt[:30]}...")
        
        try:
            result = self.text_to_image.generate_image(
                prompt=prompt,
                style=style,
                width=width,
                height=height,
                num_images=num_images
            )
            
            if result:
                print(f"âœ… å›¾åƒç”ŸæˆæˆåŠŸ!")
                print(f"ğŸ–¼ï¸ ç”Ÿæˆæ•°é‡: {len(result['images'])}")
                print(f"ğŸ“ å°ºå¯¸: {result['metadata']['width']}x{result['metadata']['height']}")
                print(f"ğŸ­ é£æ ¼: {result['metadata']['style']}")
                print(f"ğŸ“ ä¿å­˜è·¯å¾„: {result['saved_paths']}")
            
            return result
        except Exception as e:
            print(f"âŒ å›¾åƒç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    def create_slideshow_video(self, image_paths: list, duration_per_image: float = 3.0):
        if not (IMAGE_GENERATION_AVAILABLE and VIDEO_GENERATION_AVAILABLE):
            print("âŒ å›¾ç‰‡è½¬è§†é¢‘åŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…ä¾èµ–: pip install -r requirements-image.txt requirements-video.txt")
            return None
        
        if not self.image_to_video:
            print("âŒ å›¾ç‰‡è½¬è§†é¢‘æ¨¡å—æœªåˆå§‹åŒ–")
            return None
        
        print(f"æ­£åœ¨åˆ›å»ºå¹»ç¯ç‰‡è§†é¢‘ï¼Œå›¾ç‰‡æ•°é‡: {len(image_paths)}")
        
        try:
            result = self.image_to_video.create_slideshow_video(
                image_paths=image_paths,
                duration_per_image=duration_per_image
            )
            
            if result:
                file_size = result['metadata']['file_size'] / (1024 * 1024)
                print(f"âœ… å¹»ç¯ç‰‡è§†é¢‘åˆ›å»ºæˆåŠŸ!")
                print(f"ğŸ¥ è§†é¢‘ä¿å­˜è‡³: {result['video_path']}")
                print(f"â±ï¸ æ€»æ—¶é•¿: {result['metadata']['total_duration']}ç§’")
                print(f"ğŸ’¾ æ–‡ä»¶å¤§å°: {file_size:.1f} MB")
            
            return result
        except Exception as e:
            print(f"âŒ è§†é¢‘åˆ›å»ºå¤±è´¥: {str(e)}")
            return None
    
    def interactive_mode(self):
        print("ğŸ¤– æ¬¢è¿ä½¿ç”¨AIå†…å®¹åˆ›ä½œç³»ç»Ÿ!")
        print("æ”¯æŒçš„åŠŸèƒ½:")
        print("1. æ–‡ç« å†™ä½œ")
        print("2. å°è¯´åˆ›ä½œ") 
        print("3. è¯­éŸ³è¯†åˆ«")
        if VIDEO_GENERATION_AVAILABLE:
            print("4. è§†é¢‘ç”Ÿæˆ")
        else:
            print("4. è§†é¢‘ç”Ÿæˆ (ä¸å¯ç”¨ - éœ€è¦å®‰è£…é¢å¤–ä¾èµ–)")
        print("5. æç¤ºè¯ä¼˜åŒ–")
        if IMAGE_GENERATION_AVAILABLE:
            print("6. æ–‡æœ¬ç”Ÿæˆå›¾ç‰‡")
            print("7. å›¾ç‰‡è½¬è§†é¢‘")
        else:
            print("6. æ–‡æœ¬ç”Ÿæˆå›¾ç‰‡ (ä¸å¯ç”¨ - éœ€è¦å®‰è£…é¢å¤–ä¾èµ–)")
            print("7. å›¾ç‰‡è½¬è§†é¢‘ (ä¸å¯ç”¨ - éœ€è¦å®‰è£…é¢å¤–ä¾èµ–)")
        print("0. é€€å‡º")
        print("-" * 50)
        
        while True:
            try:
                choice = input("\nè¯·é€‰æ‹©åŠŸèƒ½ (0-7): ").strip()
                
                if choice == "0":
                    print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨AIå†…å®¹åˆ›ä½œç³»ç»Ÿ!")
                    break
                elif choice == "1":
                    self._interactive_article()
                elif choice == "2":
                    self._interactive_novel()
                elif choice == "3":
                    self._interactive_audio()
                elif choice == "4":
                    self._interactive_video()
                elif choice == "5":
                    self._interactive_prompt()
                elif choice == "6":
                    self._interactive_image_generation()
                elif choice == "7":
                    self._interactive_image_to_video()
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥0-7ä¹‹é—´çš„æ•°å­—")
            
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
    
    def _interactive_article(self):
        topic = input("è¯·è¾“å…¥æ–‡ç« ä¸»é¢˜: ").strip()
        if not topic:
            print("âŒ ä¸»é¢˜ä¸èƒ½ä¸ºç©º")
            return
        
        print("æ–‡ç« é£æ ¼é€‰é¡¹: informative, narrative, persuasive, technical, casual")
        style = input("è¯·é€‰æ‹©æ–‡ç« é£æ ¼ (é»˜è®¤: informative): ").strip() or "informative"
        
        print("æ–‡ç« é•¿åº¦é€‰é¡¹: short, medium, long")
        length = input("è¯·é€‰æ‹©æ–‡ç« é•¿åº¦ (é»˜è®¤: medium): ").strip() or "medium"
        
        self.generate_article(topic, style, length)
    
    def _interactive_novel(self):
        print("å°è¯´åˆ›ä½œé€‰é¡¹:")
        print("1. ç”Ÿæˆç« èŠ‚")
        print("2. ç”Ÿæˆå¤§çº²")
        
        choice = input("è¯·é€‰æ‹© (1-2): ").strip()
        
        if choice == "1":
            plot = input("è¯·è¾“å…¥ç« èŠ‚å‰§æƒ…: ").strip()
            if not plot:
                print("âŒ å‰§æƒ…ä¸èƒ½ä¸ºç©º")
                return
            
            characters = input("è¯·è¾“å…¥ä¸»è¦äººç‰© (å¯é€‰): ").strip()
            setting = input("è¯·è¾“å…¥èƒŒæ™¯è®¾å®š (å¯é€‰): ").strip()
            
            try:
                chapter_num = int(input("è¯·è¾“å…¥ç« èŠ‚ç¼–å· (é»˜è®¤: 1): ").strip() or "1")
            except ValueError:
                chapter_num = 1
            
            self.generate_novel_chapter(plot, characters, setting, chapter_num)
        
        elif choice == "2":
            theme = input("è¯·è¾“å…¥å°è¯´ä¸»é¢˜: ").strip()
            if not theme:
                print("âŒ ä¸»é¢˜ä¸èƒ½ä¸ºç©º")
                return
            
            genre = input("è¯·è¾“å…¥å°è¯´ç±»å‹ (é»˜è®¤: ç°ä»£): ").strip() or "ç°ä»£"
            length = input("è¯·è¾“å…¥å°è¯´é•¿åº¦ (é»˜è®¤: ä¸­ç¯‡): ").strip() or "ä¸­ç¯‡"
            
            self.generate_story_outline(theme, genre, length)
    
    def _interactive_audio(self):
        audio_path = input("è¯·è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„: ").strip()
        if not audio_path:
            print("âŒ æ–‡ä»¶è·¯å¾„ä¸èƒ½ä¸ºç©º")
            return
        
        print("è¯­è¨€é€‰é¡¹: zh (ä¸­æ–‡), en (è‹±æ–‡)")
        language = input("è¯·é€‰æ‹©è¯­è¨€ (é»˜è®¤: zh): ").strip() or "zh"
        
        print("æ‘˜è¦ç±»å‹: ç®€è¦, è¯¦ç»†, è¦ç‚¹, ä¼šè®®çºªè¦")
        summary_type = input("è¯·é€‰æ‹©æ‘˜è¦ç±»å‹ (é»˜è®¤: è¯¦ç»†): ").strip() or "è¯¦ç»†"
        
        self.process_audio(audio_path, language, summary_type)
    
    def _interactive_video(self):
        text_prompt = input("è¯·è¾“å…¥è§†é¢‘å†…å®¹æè¿°: ").strip()
        if not text_prompt:
            print("âŒ å†…å®¹æè¿°ä¸èƒ½ä¸ºç©º")
            return
        
        print("è§†é¢‘é£æ ¼: æ•™è‚², è¥é”€, æ•…äº‹, è§£è¯´, ç¤¾äº¤")
        video_style = input("è¯·é€‰æ‹©è§†é¢‘é£æ ¼ (é»˜è®¤: æ•™è‚²): ").strip() or "æ•™è‚²"
        
        try:
            duration = int(input("è¯·è¾“å…¥è§†é¢‘æ—¶é•¿/ç§’ (é»˜è®¤: 30): ").strip() or "30")
        except ValueError:
            duration = 30
        
        print("è¾“å‡ºç±»å‹: text_video (æ–‡å­—è§†é¢‘), slideshow (å¹»ç¯ç‰‡)")
        output_type = input("è¯·é€‰æ‹©è¾“å‡ºç±»å‹ (é»˜è®¤: text_video): ").strip() or "text_video"
        
        self.generate_video(text_prompt, video_style, duration, output_type)
    
    def _interactive_prompt(self):
        original_prompt = input("è¯·è¾“å…¥éœ€è¦ä¼˜åŒ–çš„æç¤ºè¯: ").strip()
        if not original_prompt:
            print("âŒ æç¤ºè¯ä¸èƒ½ä¸ºç©º")
            return
        
        print("ä¼˜åŒ–ç›®æ ‡: å…¨é¢ä¼˜åŒ–, æé«˜æ¸…æ™°åº¦, å¢å¼ºå…·ä½“æ€§, æ”¹è¿›ç»“æ„, æå‡å¯æ“ä½œæ€§")
        goal = input("è¯·é€‰æ‹©ä¼˜åŒ–ç›®æ ‡ (é»˜è®¤: å…¨é¢ä¼˜åŒ–): ").strip() or "å…¨é¢ä¼˜åŒ–"
        
        print("åº”ç”¨é¢†åŸŸ: é€šç”¨, å†™ä½œ, åˆ†æ, åˆ›æ„, æŠ€æœ¯, æ•™è‚², è¥é”€")
        domain = input("è¯·é€‰æ‹©åº”ç”¨é¢†åŸŸ (é»˜è®¤: é€šç”¨): ").strip() or "é€šç”¨"
        
        result = self.optimize_prompt(original_prompt, goal, domain)
        
        if result:
            print("\n" + "="*50)
            print("ğŸ“Š åˆ†æç»“æœ:")
            print(result['analysis'].get('analysis', 'åˆ†æä¿¡æ¯ä¸å¯ç”¨'))
            print("\n" + "="*50)
            print("âœ¨ ä¼˜åŒ–ç»“æœ:")
            print(result['optimization'].get('result', 'ä¼˜åŒ–ä¿¡æ¯ä¸å¯ç”¨'))
    
    def _interactive_image_generation(self):
        if not IMAGE_GENERATION_AVAILABLE:
            print("âŒ å›¾åƒç”ŸæˆåŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…å›¾åƒç”Ÿæˆä¾èµ–: pip install -r requirements-image.txt")
            return
        
        prompt = input("è¯·è¾“å…¥å›¾ç‰‡æè¿°: ").strip()
        if not prompt:
            print("âŒ å›¾ç‰‡æè¿°ä¸èƒ½ä¸ºç©º")
            return
        
        print("è‰ºæœ¯é£æ ¼: å†™å®, åŠ¨æ¼«, æ²¹ç”», æ°´å½©, ç´ æ, å¡é€š, ç§‘å¹», æ¢¦å¹»")
        style = input("è¯·é€‰æ‹©è‰ºæœ¯é£æ ¼ (é»˜è®¤: å†™å®): ").strip() or "å†™å®"
        
        try:
            width = int(input("è¯·è¾“å…¥å›¾ç‰‡å®½åº¦ (é»˜è®¤: 512): ").strip() or "512")
            height = int(input("è¯·è¾“å…¥å›¾ç‰‡é«˜åº¦ (é»˜è®¤: 512): ").strip() or "512")
            num_images = int(input("è¯·è¾“å…¥ç”Ÿæˆæ•°é‡ (é»˜è®¤: 1): ").strip() or "1")
        except ValueError:
            width, height, num_images = 512, 512, 1
        
        self.generate_image(prompt, style, width, height, num_images)
    
    def _interactive_image_to_video(self):
        if not (IMAGE_GENERATION_AVAILABLE and VIDEO_GENERATION_AVAILABLE):
            print("âŒ å›¾ç‰‡è½¬è§†é¢‘åŠŸèƒ½ä¸å¯ç”¨")
            print("ğŸ’¡ è¯·å®‰è£…ä¾èµ–: pip install -r requirements-image.txt requirements-video.txt")
            return
        
        print("å›¾ç‰‡è½¬è§†é¢‘åŠŸèƒ½:")
        print("è¯·è¾“å…¥å›¾ç‰‡æ–‡ä»¶è·¯å¾„ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œè¾“å…¥ç©ºè¡Œç»“æŸ:")
        
        image_paths = []
        while True:
            path = input("å›¾ç‰‡è·¯å¾„: ").strip()
            if not path:
                break
            if os.path.exists(path):
                image_paths.append(path)
                print(f"âœ… æ·»åŠ å›¾ç‰‡: {os.path.basename(path)}")
            else:
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        
        if not image_paths:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶")
            return
        
        try:
            duration = float(input("æ¯å¼ å›¾ç‰‡æ˜¾ç¤ºæ—¶é•¿/ç§’ (é»˜è®¤: 3.0): ").strip() or "3.0")
        except ValueError:
            duration = 3.0
        
        self.create_slideshow_video(image_paths, duration)

def main():
    parser = argparse.ArgumentParser(description="AIå†…å®¹åˆ›ä½œç³»ç»Ÿ")
    parser.add_argument("--interactive", "-i", action="store_true", help="äº¤äº’æ¨¡å¼")
    parser.add_argument("--article", help="ç”Ÿæˆæ–‡ç« ï¼ŒæŒ‡å®šä¸»é¢˜")
    parser.add_argument("--audio", help="å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼ŒæŒ‡å®šæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--video", help="ç”Ÿæˆè§†é¢‘ï¼ŒæŒ‡å®šå†…å®¹æè¿°")
    parser.add_argument("--optimize-prompt", help="ä¼˜åŒ–æç¤ºè¯")
    parser.add_argument("--generate-image", help="ç”Ÿæˆå›¾ç‰‡ï¼ŒæŒ‡å®šæè¿°")
    parser.add_argument("--image-to-video", help="å›¾ç‰‡è½¬è§†é¢‘ï¼ŒæŒ‡å®šå›¾ç‰‡ç›®å½•")
    
    args = parser.parse_args()
    
    system = AI2CSystem()
    
    if args.interactive or len(sys.argv) == 1:
        system.interactive_mode()
    elif args.article:
        system.generate_article(args.article)
    elif args.audio:
        system.process_audio(args.audio)
    elif args.video:
        system.generate_video(args.video)
    elif args.optimize_prompt:
        system.optimize_prompt(args.optimize_prompt)
    elif args.generate_image:
        system.generate_image(args.generate_image)
    elif args.image_to_video:
        import glob
        image_paths = glob.glob(os.path.join(args.image_to_video, "*.{jpg,jpeg,png,webp}"))
        if image_paths:
            system.create_slideshow_video(image_paths)
        else:
            print(f"âŒ åœ¨ç›®å½• {args.image_to_video} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
    else:
        parser.print_help()

if __name__ == "__main__":
    main()