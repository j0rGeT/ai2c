import os
import cv2
import numpy as np
from datetime import datetime
from typing import Dict, Any, List, Optional, Union
from PIL import Image
import json

# å¯é€‰ä¾èµ–æ£€æŸ¥
try:
    from moviepy.editor import ImageClip, VideoFileClip, concatenate_videoclips, CompositeVideoClip
    from moviepy.video.fx import resize, fadein, fadeout
    MOVIEPY_AVAILABLE = True
except ImportError:
    MOVIEPY_AVAILABLE = False
    print("âš ï¸ è§†é¢‘ç”Ÿæˆä¾èµ–æœªå®‰è£…ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
    print("pip install -r requirements-video.txt")

class ImageToVideoGenerator:
    def __init__(self):
        self.output_dir = "./outputs/videos"
        self.temp_dir = "./temp"
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(self.temp_dir, exist_ok=True)
        self.moviepy_available = MOVIEPY_AVAILABLE
        
        # é¢„å®šä¹‰çš„è§†é¢‘æ•ˆæœ
        self.effects = {
            "é™æ€": "static",
            "æ·¡å…¥æ·¡å‡º": "fade",
            "æ”¾å¤§ç¼©å°": "zoom",
            "å¹³ç§»": "pan",
            "æ—‹è½¬": "rotate",
            "å¹»ç¯ç‰‡": "slideshow"
        }
        
        # è½¬åœºæ•ˆæœ
        self.transitions = {
            "åˆ‡æ¢": "cut",
            "æ·¡åŒ–": "fade",
            "æ»‘åŠ¨": "slide",
            "æ¨æ‹‰": "push"
        }
    
    def _check_dependencies(self):
        """æ£€æŸ¥è§†é¢‘ç”Ÿæˆä¾èµ–"""
        if not self.moviepy_available:
            raise ImportError(
                "å›¾ç‰‡è½¬è§†é¢‘åŠŸèƒ½éœ€è¦é¢å¤–ä¾èµ–ï¼Œè¯·è¿è¡Œ: pip install -r requirements-video.txt"
            )
    
    def load_images(self, image_paths: List[str]) -> List[Image.Image]:
        """åŠ è½½å›¾åƒæ–‡ä»¶"""
        images = []
        
        for path in image_paths:
            try:
                if isinstance(path, str) and os.path.exists(path):
                    image = Image.open(path)
                    images.append(image)
                    print(f"âœ… åŠ è½½å›¾åƒ: {os.path.basename(path)}")
                elif hasattr(path, 'save'):  # PIL Imageå¯¹è±¡
                    images.append(path)
                    print(f"âœ… åŠ è½½PILå›¾åƒå¯¹è±¡")
                else:
                    print(f"âŒ æ— æ³•åŠ è½½å›¾åƒ: {path}")
            except Exception as e:
                print(f"âŒ åŠ è½½å›¾åƒå¤±è´¥ {path}: {e}")
        
        return images
    
    def create_slideshow_video(
        self,
        image_paths: List[Union[str, Image.Image]],
        duration_per_image: float = 3.0,
        transition_duration: float = 0.5,
        output_size: tuple = (1920, 1080),
        fps: int = 24,
        background_music: str = None
    ) -> Dict[str, Any]:
        """åˆ›å»ºå¹»ç¯ç‰‡è§†é¢‘"""
        self._check_dependencies()
        
        print(f"ğŸ¬ å¼€å§‹åˆ›å»ºå¹»ç¯ç‰‡è§†é¢‘...")
        print(f"ğŸ“¸ å›¾ç‰‡æ•°é‡: {len(image_paths)}")
        print(f"â±ï¸ æ¯å¼ å›¾ç‰‡æ—¶é•¿: {duration_per_image}ç§’")
        
        # åŠ è½½å›¾åƒ
        images = []
        for item in image_paths:
            if isinstance(item, str):
                if os.path.exists(item):
                    images.append(item)
                else:
                    print(f"âš ï¸ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {item}")
            elif hasattr(item, 'save'):  # PIL Image
                # ä¿å­˜PILå›¾åƒåˆ°ä¸´æ—¶æ–‡ä»¶
                temp_path = os.path.join(self.temp_dir, f"temp_img_{len(images)}.png")
                item.save(temp_path)
                images.append(temp_path)
        
        if not images:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„å›¾åƒæ–‡ä»¶")
        
        try:
            clips = []
            
            for i, image_path in enumerate(images):
                print(f"ğŸ”„ å¤„ç†å›¾åƒ {i+1}/{len(images)}")
                
                # åˆ›å»ºå›¾åƒå‰ªè¾‘
                clip = ImageClip(image_path, duration=duration_per_image)
                
                # è°ƒæ•´å¤§å°
                clip = clip.resize(output_size)
                
                # æ·»åŠ æ·¡å…¥æ·¡å‡ºæ•ˆæœ
                if transition_duration > 0:
                    if i > 0:  # ä¸æ˜¯ç¬¬ä¸€å¼ å›¾ç‰‡
                        clip = clip.fadein(transition_duration)
                    if i < len(images) - 1:  # ä¸æ˜¯æœ€åä¸€å¼ å›¾ç‰‡
                        clip = clip.fadeout(transition_duration)
                
                clips.append(clip)
            
            # åˆå¹¶æ‰€æœ‰å‰ªè¾‘
            final_video = concatenate_videoclips(clips, method="compose")
            
            # æ·»åŠ èƒŒæ™¯éŸ³ä¹
            if background_music and os.path.exists(background_music):
                from moviepy.editor import AudioFileClip
                audio = AudioFileClip(background_music)
                
                if audio.duration > final_video.duration:
                    audio = audio.subclip(0, final_video.duration)
                else:
                    audio = audio.loop(duration=final_video.duration)
                
                final_video = final_video.set_audio(audio.volumex(0.3))
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"slideshow_{timestamp}.mp4"
            output_path = os.path.join(self.output_dir, output_filename)
            
            # è¾“å‡ºè§†é¢‘
            print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜è§†é¢‘åˆ°: {output_path}")
            final_video.write_videofile(
                output_path,
                fps=fps,
                codec='libx264',
                audio_codec='aac' if background_music else None
            )
            
            # æ¸…ç†èµ„æº
            final_video.close()
            for clip in clips:
                clip.close()
            
            result = {
                "video_path": output_path,
                "metadata": {
                    "image_count": len(images),
                    "duration_per_image": duration_per_image,
                    "transition_duration": transition_duration,
                    "total_duration": len(images) * duration_per_image,
                    "output_size": output_size,
                    "fps": fps,
                    "background_music": background_music,
                    "created_at": datetime.now().isoformat(),
                    "file_size": os.path.getsize(output_path) if os.path.exists(output_path) else 0
                }
            }
            
            print(f"âœ… å¹»ç¯ç‰‡è§†é¢‘åˆ›å»ºå®Œæˆ!")
            return result
            
        except Exception as e:
            print(f"âŒ è§†é¢‘åˆ›å»ºå¤±è´¥: {e}")
            raise e
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self._cleanup_temp_images()
    
    def create_animated_video(
        self,
        image_path: Union[str, Image.Image],
        animation_type: str = "zoom",
        duration: float = 5.0,
        output_size: tuple = (1920, 1080),
        fps: int = 30
    ) -> Dict[str, Any]:
        """åˆ›å»ºå•å›¾ç‰‡åŠ¨ç”»è§†é¢‘"""
        self._check_dependencies()
        
        print(f"ğŸ¬ åˆ›å»ºåŠ¨ç”»è§†é¢‘ï¼Œæ•ˆæœ: {animation_type}")
        
        # å¤„ç†è¾“å…¥å›¾åƒ
        if isinstance(image_path, str):
            if not os.path.exists(image_path):
                raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            temp_image_path = image_path
        else:  # PIL Image
            temp_image_path = os.path.join(self.temp_dir, "temp_animation.png")
            image_path.save(temp_image_path)
        
        try:
            clip = ImageClip(temp_image_path, duration=duration)
            clip = clip.resize(output_size)
            
            # æ ¹æ®åŠ¨ç”»ç±»å‹åº”ç”¨æ•ˆæœ
            if animation_type == "zoom":
                # ç¼©æ”¾æ•ˆæœ
                def zoom_effect(get_frame, t):
                    frame = get_frame(t)
                    zoom_factor = 1 + (t / duration) * 0.3  # é€æ¸æ”¾å¤§30%
                    h, w = frame.shape[:2]
                    new_h, new_w = int(h * zoom_factor), int(w * zoom_factor)
                    
                    # è°ƒæ•´å¤§å°
                    resized = cv2.resize(frame, (new_w, new_h))
                    
                    # å±…ä¸­è£å‰ª
                    start_x = (new_w - w) // 2
                    start_y = (new_h - h) // 2
                    result = resized[start_y:start_y + h, start_x:start_x + w]
                    
                    return result
                
                clip = clip.fl(zoom_effect)
            
            elif animation_type == "pan":
                # å¹³ç§»æ•ˆæœ
                def pan_effect(get_frame, t):
                    frame = get_frame(t)
                    h, w = frame.shape[:2]
                    
                    # åˆ›å»ºç¨å¤§çš„canvas
                    canvas_w, canvas_h = int(w * 1.2), int(h * 1.2)
                    canvas = np.zeros((canvas_h, canvas_w, 3), dtype=np.uint8)
                    
                    # è®¡ç®—ä½ç½®
                    progress = t / duration
                    start_x = int((canvas_w - w) * progress)
                    start_y = int((canvas_h - h) * 0.1)
                    
                    # æ”¾ç½®å›¾åƒ
                    canvas[start_y:start_y + h, start_x:start_x + w] = frame
                    
                    # è£å‰ªå›åŸå§‹å¤§å°
                    crop_x = (canvas_w - w) // 2
                    crop_y = (canvas_h - h) // 2
                    result = canvas[crop_y:crop_y + h, crop_x:crop_x + w]
                    
                    return result
                
                clip = clip.fl(pan_effect)
            
            elif animation_type == "fade":
                # æ·¡å…¥æ·¡å‡ºæ•ˆæœ
                fade_duration = min(1.0, duration / 3)
                clip = clip.fadein(fade_duration).fadeout(fade_duration)
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"animated_{animation_type}_{timestamp}.mp4"
            output_path = os.path.join(self.output_dir, output_filename)
            
            print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜åŠ¨ç”»è§†é¢‘...")
            clip.write_videofile(
                output_path,
                fps=fps,
                codec='libx264'
            )
            
            clip.close()
            
            result = {
                "video_path": output_path,
                "metadata": {
                    "animation_type": animation_type,
                    "duration": duration,
                    "output_size": output_size,
                    "fps": fps,
                    "created_at": datetime.now().isoformat(),
                    "file_size": os.path.getsize(output_path) if os.path.exists(output_path) else 0
                }
            }
            
            print(f"âœ… åŠ¨ç”»è§†é¢‘åˆ›å»ºå®Œæˆ!")
            return result
            
        except Exception as e:
            print(f"âŒ åŠ¨ç”»è§†é¢‘åˆ›å»ºå¤±è´¥: {e}")
            raise e
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_image_path != image_path and os.path.exists(temp_image_path):
                os.remove(temp_image_path)
    
    def create_comparison_video(
        self,
        before_image: Union[str, Image.Image],
        after_image: Union[str, Image.Image],
        comparison_type: str = "side_by_side",
        duration: float = 10.0,
        transition_point: float = 5.0,
        output_size: tuple = (1920, 1080)
    ) -> Dict[str, Any]:
        """åˆ›å»ºå¯¹æ¯”è§†é¢‘"""
        self._check_dependencies()
        
        print(f"ğŸ¬ åˆ›å»ºå¯¹æ¯”è§†é¢‘ï¼Œç±»å‹: {comparison_type}")
        
        # å¤„ç†è¾“å…¥å›¾åƒ
        temp_paths = []
        for i, image in enumerate([before_image, after_image]):
            if isinstance(image, str):
                temp_paths.append(image)
            else:
                temp_path = os.path.join(self.temp_dir, f"temp_compare_{i}.png")
                image.save(temp_path)
                temp_paths.append(temp_path)
        
        try:
            clip1 = ImageClip(temp_paths[0], duration=duration).resize(output_size)
            clip2 = ImageClip(temp_paths[1], duration=duration).resize(output_size)
            
            if comparison_type == "side_by_side":
                # å¹¶æ’å¯¹æ¯”
                # è°ƒæ•´æ¯ä¸ªå›¾åƒä¸ºä¸€åŠå®½åº¦
                half_width = output_size[0] // 2
                clip1 = clip1.resize((half_width, output_size[1])).set_position(('left'))
                clip2 = clip2.resize((half_width, output_size[1])).set_position(('right'))
                
                final_clip = CompositeVideoClip([clip1, clip2])
                
            elif comparison_type == "transition":
                # è½¬åœºå¯¹æ¯”
                clip1 = clip1.set_duration(transition_point).fadeout(0.5)
                clip2 = clip2.set_start(transition_point).fadein(0.5)
                
                final_clip = CompositeVideoClip([clip1, clip2])
                
            else:  # before_after
                # å‰åå¯¹æ¯”
                final_clip = concatenate_videoclips([clip1.set_duration(duration/2), 
                                                   clip2.set_duration(duration/2)])
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"comparison_{comparison_type}_{timestamp}.mp4"
            output_path = os.path.join(self.output_dir, output_filename)
            
            print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜å¯¹æ¯”è§†é¢‘...")
            final_clip.write_videofile(
                output_path,
                fps=24,
                codec='libx264'
            )
            
            # æ¸…ç†èµ„æº
            final_clip.close()
            clip1.close()
            clip2.close()
            
            result = {
                "video_path": output_path,
                "metadata": {
                    "comparison_type": comparison_type,
                    "duration": duration,
                    "transition_point": transition_point if comparison_type == "transition" else None,
                    "output_size": output_size,
                    "created_at": datetime.now().isoformat(),
                    "file_size": os.path.getsize(output_path) if os.path.exists(output_path) else 0
                }
            }
            
            print(f"âœ… å¯¹æ¯”è§†é¢‘åˆ›å»ºå®Œæˆ!")
            return result
            
        except Exception as e:
            print(f"âŒ å¯¹æ¯”è§†é¢‘åˆ›å»ºå¤±è´¥: {e}")
            raise e
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for temp_path in temp_paths:
                if temp_path != before_image and temp_path != after_image and os.path.exists(temp_path):
                    os.remove(temp_path)
    
    def batch_create_videos(
        self,
        image_groups: List[List[str]],
        video_type: str = "slideshow",
        **kwargs
    ) -> Dict[str, Any]:
        """æ‰¹é‡åˆ›å»ºè§†é¢‘"""
        results = []
        failed_groups = []
        
        for i, image_group in enumerate(image_groups):
            print(f"\nğŸ”„ å¤„ç†ç¬¬ {i+1}/{len(image_groups)} ç»„å›¾ç‰‡")
            
            try:
                if video_type == "slideshow":
                    result = self.create_slideshow_video(image_group, **kwargs)
                else:
                    # å¯¹äºå•å›¾åŠ¨ç”»ï¼Œåªå–ç¬¬ä¸€å¼ å›¾ç‰‡
                    result = self.create_animated_video(image_group[0], **kwargs)
                
                results.append({
                    "group_index": i,
                    "image_group": image_group,
                    "result": result
                })
                
            except Exception as e:
                print(f"âŒ ç¬¬ {i+1} ç»„å¤„ç†å¤±è´¥: {e}")
                failed_groups.append({
                    "group_index": i,
                    "image_group": image_group,
                    "error": str(e)
                })
        
        return {
            "successful_results": results,
            "failed_groups": failed_groups,
            "total_processed": len(image_groups),
            "success_count": len(results),
            "failure_count": len(failed_groups)
        }
    
    def _cleanup_temp_images(self):
        """æ¸…ç†ä¸´æ—¶å›¾åƒæ–‡ä»¶"""
        try:
            for filename in os.listdir(self.temp_dir):
                if filename.startswith("temp_") and filename.endswith((".png", ".jpg", ".jpeg")):
                    filepath = os.path.join(self.temp_dir, filename)
                    os.remove(filepath)
        except Exception as e:
            print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def get_video_info(self, video_path: str) -> Dict[str, Any]:
        """è·å–è§†é¢‘ä¿¡æ¯"""
        if not os.path.exists(video_path):
            return None
        
        try:
            clip = VideoFileClip(video_path)
            info = {
                "duration": clip.duration,
                "fps": clip.fps,
                "size": clip.size,
                "file_size": os.path.getsize(video_path)
            }
            clip.close()
            return info
        except Exception as e:
            print(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
            return None