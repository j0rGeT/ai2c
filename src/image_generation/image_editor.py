import os
import torch
from datetime import datetime
from typing import Dict, Any, List, Optional, Union
from PIL import Image
import numpy as np
from ..content_generation.llm_client import LLMClient

# å¯é€‰ä¾èµ–æ£€æŸ¥
try:
    from diffusers import (
        QwenImageEditPipeline, 
        StableDiffusionInpaintPipeline,
        StableDiffusionXLInpaintPipeline,
        ControlNetModel,
        StableDiffusionControlNetInpaintPipeline
    )
    QWEN_IMAGE_EDIT_AVAILABLE = True
except ImportError:
    QWEN_IMAGE_EDIT_AVAILABLE = False
    print("âš ï¸ Qwenå›¾åƒç¼–è¾‘ä¾èµ–æœªå®‰è£…ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
    print("pip install -r requirements-image.txt")

# å…¶ä»–æ¨¡å‹ä¾èµ–
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False

try:
    from segment_anything import SamPredictor, sam_model_registry
    SAM_AVAILABLE = True
except ImportError:
    SAM_AVAILABLE = False

class ImageEditor:
    def __init__(self):
        self.llm_client = LLMClient()
        self.output_dir = "./outputs/images/edited"
        os.makedirs(self.output_dir, exist_ok=True)
        self.qwen_available = QWEN_IMAGE_EDIT_AVAILABLE
        self.pipeline = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # é¢„å®šä¹‰çš„ç¼–è¾‘æ¨¡æ¿
        self.editing_templates = {
            "è§†è§’è½¬æ¢": {
                "ä»æ­£é¢çœ‹": "Change the view to front view, clear and detailed",
                "ä»ä¾§é¢çœ‹": "Change the view to side view, clear and detailed", 
                "ä»èƒŒé¢çœ‹": "Change the view to back view, clear and detailed",
                "ä»ä¸Šå¾€ä¸‹çœ‹": "Change the view to top-down view, bird's eye view",
                "ä»ä¸‹å¾€ä¸Šçœ‹": "Change the view to bottom-up view, low angle view",
                "ä¿¯è§†å›¾": "Convert to aerial view, overhead perspective",
                "ä»°è§†å›¾": "Convert to upward view, worm's eye view"
            },
            "é£æ ¼è½¬æ¢": {
                "æ²¹ç”»é£æ ¼": "Convert to oil painting style, artistic brush strokes",
                "æ°´å½©é£æ ¼": "Convert to watercolor style, soft and flowing",
                "ç´ æé£æ ¼": "Convert to pencil sketch style, black and white drawing",
                "åŠ¨æ¼«é£æ ¼": "Convert to anime style, manga artwork",
                "ç…§ç‰‡é£æ ¼": "Convert to photorealistic style, highly detailed",
                "å°è±¡æ´¾": "Convert to impressionist painting style",
                "æŠ½è±¡è‰ºæœ¯": "Convert to abstract art style"
            },
            "ç¯å¢ƒå˜æ¢": {
                "ç™½å¤©è½¬å¤œæ™š": "Change from day to night, add moonlight and stars",
                "å¤œæ™šè½¬ç™½å¤©": "Change from night to day, add bright sunlight",
                "æ™´å¤©è½¬é›¨å¤©": "Change to rainy weather, add rain drops and clouds",
                "å®¤å†…è½¬å®¤å¤–": "Move the scene from indoor to outdoor setting",
                "ç°ä»£è½¬å¤ä»£": "Change the setting from modern to ancient times",
                "åŸå¸‚è½¬ä¹¡æ‘": "Change the setting from city to countryside",
                "æ˜¥å¤©è½¬ç§‹å¤©": "Change the season from spring to autumn"
            },
            "å¯¹è±¡å˜æ¢": {
                "æ”¹å˜é¢œè‰²": "Change the color to {color}",
                "æ”¹å˜æè´¨": "Change the material to {material}",
                "æ”¹å˜å¤§å°": "Change the size to {size}",
                "æ·»åŠ è£…é¥°": "Add decorative elements like {decoration}",
                "æ”¹å˜è¡¨æƒ…": "Change the facial expression to {expression}",
                "æ”¹å˜å§¿æ€": "Change the pose to {pose}",
                "æ”¹å˜æœè£…": "Change the clothing to {clothing}"
            },
            "è™šæ‹Ÿå½¢è±¡ç”Ÿæˆ": {
                "ç”Ÿæˆ3Dè™šæ‹Ÿäºº": "Generate a 3D virtual avatar, realistic human appearance",
                "å¡é€šè§’è‰²": "Create cartoon character avatar, stylized and cute",
                "åŠ¨æ¼«äººç‰©": "Generate anime character, manga style illustration",
                "æ¸¸æˆè§’è‰²": "Create game character design, fantasy RPG style",
                "å•†åŠ¡å½¢è±¡": "Generate professional business avatar, formal appearance",
                "æ—¶å°šæ¨¡ç‰¹": "Create fashion model avatar, trendy and stylish"
            },
            "AIæ¶ˆé™¤": {
                "ç§»é™¤å¯¹è±¡": "Remove the {object} from the image completely",
                "æ¶ˆé™¤æ°´å°": "Remove watermarks and logos from the image",
                "æ¸…é™¤èƒŒæ™¯": "Remove background, make it transparent or solid color",
                "å»é™¤æ–‡å­—": "Remove all text and writing from the image",
                "æ¶ˆé™¤ç‘•ç–µ": "Remove imperfections, spots, and blemishes",
                "åˆ é™¤äººç‰©": "Remove people from the image"
            },
            "AIé‡ç»˜": {
                "å±€éƒ¨é‡ç»˜": "Redraw the selected area with {description}",
                "èƒŒæ™¯é‡ç»˜": "Redraw the background as {background}",
                "äººç‰©é‡ç»˜": "Redraw the person with {features}",
                "ç‰©ä½“é‡ç»˜": "Redraw the object as {new_object}",
                "å…¨å›¾é‡ç»˜": "Completely redraw the image in {style} style",
                "ç»†èŠ‚é‡ç»˜": "Enhance and redraw fine details"
            },
            "è™šæ‹Ÿåœºæ™¯": {
                "ç§‘å¹»åœºæ™¯": "Transform into futuristic sci-fi environment",
                "å¥‡å¹»ä¸–ç•Œ": "Create fantasy world with magical elements",
                "å†å²åœºæ™¯": "Transform into historical setting of {period}",
                "è‡ªç„¶é£å…‰": "Create natural landscape scene with {elements}",
                "åŸå¸‚åœºæ™¯": "Generate urban cityscape environment",
                "å®¤å†…ç©ºé—´": "Create interior space design for {room_type}"
            },
            "ç©¿æ­æ¨¡æ‹Ÿ": {
                "æ¢è£…è¯•è¡£": "Change clothing to {clothing_style}",
                "é…é¥°æ­é…": "Add accessories like {accessories}",
                "å‘å‹å˜æ¢": "Change hairstyle to {hairstyle}",
                "å¦†å®¹è°ƒæ•´": "Adjust makeup style to {makeup_style}",
                "é¢œè‰²æ­é…": "Change color scheme to {color_theme}",
                "å­£èŠ‚ç©¿æ­": "Change outfit for {season} season"
            },
            "æ–‡å­—è®¾è®¡": {
                "è‰ºæœ¯å­—ä½“": "Add artistic text '{text}' with {font_style} style",
                "æ ‡é¢˜è®¾è®¡": "Design title text '{title}' with professional layout",
                "logoè®¾è®¡": "Create logo design with text '{logo_text}'",
                "ä¹¦æ³•å­—ä½“": "Add calligraphy text '{text}' in {calligraphy_style}",
                "ç«‹ä½“æ–‡å­—": "Create 3D text effect for '{text}'",
                "éœ“è™¹æ–‡å­—": "Add neon light text effect for '{text}'"
            },
            "æµ·æŠ¥ç¼–è¾‘": {
                "ç”µå½±æµ·æŠ¥": "Design movie poster style with {theme}",
                "éŸ³ä¹æµ·æŠ¥": "Create music concert poster design",
                "æ´»åŠ¨æµ·æŠ¥": "Design event poster for {event_type}",
                "äº§å“æµ·æŠ¥": "Create product advertisement poster",
                "å¤å¤æµ·æŠ¥": "Design vintage poster style with retro elements",
                "ç®€çº¦æµ·æŠ¥": "Create minimalist poster design"
            }
        }
        
        # æ¨¡å‹ç®¡é“å­˜å‚¨
        self.pipelines = {
            'qwen_edit': None,
            'inpaint': None,
            'inpaint_xl': None,
            'controlnet_inpaint': None
        }
        
        # SAMæ¨¡å‹ç”¨äºå¯¹è±¡åˆ†å‰²
        self.sam_predictor = None
    
    def _check_dependencies(self):
        """æ£€æŸ¥Qwenå›¾åƒç¼–è¾‘ä¾èµ–"""
        if not self.qwen_available:
            raise ImportError(
                "å›¾åƒç¼–è¾‘åŠŸèƒ½éœ€è¦é¢å¤–ä¾èµ–ï¼Œè¯·è¿è¡Œ: pip install -r requirements-image.txt"
            )
    
    def load_pipeline(self, model_type="qwen_edit"):
        """åŠ è½½æŒ‡å®šç±»å‹çš„å›¾åƒç¼–è¾‘æ¨¡å‹"""
        self._check_dependencies()
        
        if self.pipelines[model_type] is not None:
            return
        
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½{model_type}å›¾åƒç¼–è¾‘æ¨¡å‹...")
        
        try:
            if model_type == "qwen_edit":
                self.pipelines[model_type] = QwenImageEditPipeline.from_pretrained(
                    "Qwen/Qwen-Image-Edit",
                    torch_dtype=torch.bfloat16 if self.device == "cuda" else torch.float32,
                    use_safetensors=True
                )
            elif model_type == "inpaint":
                self.pipelines[model_type] = StableDiffusionInpaintPipeline.from_pretrained(
                    "runwayml/stable-diffusion-inpainting",
                    torch_dtype=torch.float16 if self.device == "cuda" else torch.float32
                )
            elif model_type == "inpaint_xl":
                self.pipelines[model_type] = StableDiffusionXLInpaintPipeline.from_pretrained(
                    "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
                    torch_dtype=torch.float16 if self.device == "cuda" else torch.float32
                )
            elif model_type == "controlnet_inpaint":
                controlnet = ControlNetModel.from_pretrained(
                    "lllyasviel/control_v11p_sd15_inpaint",
                    torch_dtype=torch.float16 if self.device == "cuda" else torch.float32
                )
                self.pipelines[model_type] = StableDiffusionControlNetInpaintPipeline.from_pretrained(
                    "runwayml/stable-diffusion-v1-5",
                    controlnet=controlnet,
                    torch_dtype=torch.float16 if self.device == "cuda" else torch.float32
                )
            
            if self.device == "cuda":
                self.pipelines[model_type] = self.pipelines[model_type].to(self.device)
            
            # è®¾ç½®è¿›åº¦æ¡
            self.pipelines[model_type].set_progress_bar_config(disable=None)
            
            print(f"âœ… {model_type}å›¾åƒç¼–è¾‘æ¨¡å‹åŠ è½½å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
            
        except Exception as e:
            print(f"âŒ {model_type}æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise e
    
    def optimize_edit_prompt(self, user_prompt: str, language: str = "zh") -> str:
        """ä¼˜åŒ–å›¾åƒç¼–è¾‘æç¤ºè¯"""
        if language == "zh":
            optimization_prompt = f"""
è¯·å°†ä»¥ä¸‹ä¸­æ–‡å›¾åƒç¼–è¾‘æè¿°è½¬æ¢ä¸ºé€‚åˆAIå›¾åƒç¼–è¾‘çš„è‹±æ–‡æç¤ºè¯ï¼š

ç”¨æˆ·æè¿°ï¼š{user_prompt}

è¦æ±‚ï¼š
1. è½¬æ¢ä¸ºè¯¦ç»†çš„è‹±æ–‡ç¼–è¾‘æŒ‡ä»¤
2. ä½¿ç”¨æ¸…æ™°ã€å…·ä½“çš„åŠ¨ä½œè¯æ±‡ï¼ˆchange, convert, transform, add, removeç­‰ï¼‰
3. åŒ…å«å…·ä½“çš„è§†è§‰æè¿°
4. ä¿æŒç¼–è¾‘æ„å›¾æ¸…æ™°æ˜ç¡®
5. é¿å…æ¨¡ç³Šæˆ–æŠ½è±¡çš„æè¿°

è¯·åªè¿”å›ä¼˜åŒ–åçš„è‹±æ–‡ç¼–è¾‘æç¤ºè¯ï¼š
"""
        else:
            optimization_prompt = f"""
Optimize the following prompt for AI image editing:

User prompt: {user_prompt}

Requirements:
1. Make it clear and specific for image editing
2. Use precise action words (change, convert, transform, add, remove, etc.)
3. Include specific visual descriptions
4. Keep the editing intent clear
5. Avoid vague or abstract descriptions

Return only the optimized editing prompt:
"""
        
        try:
            optimized = self.llm_client.generate(
                optimization_prompt,
                max_tokens=150,
                temperature=0.3
            )
            return optimized.strip()
        except Exception as e:
            print(f"æç¤ºè¯ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æç¤ºè¯: {e}")
            return user_prompt
    
    def edit_image(
        self,
        image: Union[str, Image.Image],
        edit_prompt: str,
        negative_prompt: str = "",
        true_cfg_scale: float = 4.0,
        num_inference_steps: int = 50,
        seed: int = None,
        optimize_prompt: bool = True
    ) -> Dict[str, Any]:
        """ç¼–è¾‘å›¾åƒ"""
        self._check_dependencies()
        
        # åŠ è½½æ¨¡å‹
        if self.pipelines['qwen_edit'] is None:
            self.load_pipeline('qwen_edit')
        
        # å¤„ç†è¾“å…¥å›¾åƒ
        if isinstance(image, str):
            if not os.path.exists(image):
                raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image}")
            input_image = Image.open(image).convert("RGB")
            image_source = image
        else:
            input_image = image.convert("RGB")
            image_source = "PIL Image"
        
        # ä¼˜åŒ–ç¼–è¾‘æç¤ºè¯
        if optimize_prompt:
            print("ğŸ”„ æ­£åœ¨ä¼˜åŒ–ç¼–è¾‘æç¤ºè¯...")
            edit_prompt = self.optimize_edit_prompt(edit_prompt)
            print(f"âœ¨ ä¼˜åŒ–åçš„æç¤ºè¯: {edit_prompt}")
        
        # è®¾ç½®éšæœºç§å­
        if seed is None:
            seed = np.random.randint(0, 2**32 - 1)
        
        print(f"ğŸ¨ å¼€å§‹ç¼–è¾‘å›¾åƒ...")
        print(f"ğŸ“ ç¼–è¾‘æŒ‡ä»¤: {edit_prompt}")
        print(f"ğŸ¯ åŸå›¾å°ºå¯¸: {input_image.size}")
        
        try:
            # å‡†å¤‡è¾“å…¥å‚æ•°
            inputs = {
                "image": input_image,
                "prompt": edit_prompt,
                "generator": torch.manual_seed(seed),
                "true_cfg_scale": true_cfg_scale,
                "negative_prompt": negative_prompt,
                "num_inference_steps": num_inference_steps,
            }
            
            # æ‰§è¡Œå›¾åƒç¼–è¾‘
            with torch.inference_mode():
                output = self.pipelines['qwen_edit'](**inputs)
                edited_image = output.images[0]
            
            # ä¿å­˜ç¼–è¾‘åçš„å›¾åƒ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"edited_{timestamp}_seed_{seed}.png"
            output_path = os.path.join(self.output_dir, filename)
            edited_image.save(output_path)
            
            result = {
                "original_image": input_image,
                "edited_image": edited_image,
                "output_path": output_path,
                "metadata": {
                    "image_source": image_source,
                    "edit_prompt": edit_prompt,
                    "negative_prompt": negative_prompt,
                    "true_cfg_scale": true_cfg_scale,
                    "num_inference_steps": num_inference_steps,
                    "seed": seed,
                    "original_size": input_image.size,
                    "edited_size": edited_image.size,
                    "edited_at": datetime.now().isoformat()
                }
            }
            
            print(f"âœ… å›¾åƒç¼–è¾‘å®Œæˆ!")
            print(f"ğŸ“ ä¿å­˜è·¯å¾„: {output_path}")
            
            return result
            
        except Exception as e:
            print(f"âŒ å›¾åƒç¼–è¾‘å¤±è´¥: {e}")
            raise e
    
    def batch_edit_images(
        self,
        images: List[Union[str, Image.Image]],
        edit_prompt: str,
        **kwargs
    ) -> Dict[str, Any]:
        """æ‰¹é‡ç¼–è¾‘å›¾åƒ"""
        results = []
        failed_images = []
        
        for i, image in enumerate(images):
            print(f"\nğŸ”„ ç¼–è¾‘ç¬¬ {i+1}/{len(images)} å¼ å›¾ç‰‡")
            
            try:
                result = self.edit_image(image, edit_prompt, **kwargs)
                results.append({
                    "index": i,
                    "image_source": image if isinstance(image, str) else f"PIL Image {i}",
                    "result": result
                })
            except Exception as e:
                print(f"âŒ ç¬¬ {i+1} å¼ å›¾ç‰‡ç¼–è¾‘å¤±è´¥: {e}")
                failed_images.append({
                    "index": i,
                    "image_source": image if isinstance(image, str) else f"PIL Image {i}",
                    "error": str(e)
                })
        
        return {
            "successful_results": results,
            "failed_images": failed_images,
            "total_processed": len(images),
            "success_count": len(results),
            "failure_count": len(failed_images)
        }
    
    def perspective_transform(
        self,
        image: Union[str, Image.Image], 
        target_view: str,
        **kwargs
    ) -> Dict[str, Any]:
        """è§†è§’è½¬æ¢"""
        view_prompts = self.editing_templates["è§†è§’è½¬æ¢"]
        
        if target_view in view_prompts:
            edit_prompt = view_prompts[target_view]
        else:
            edit_prompt = f"Change the perspective view to {target_view}, clear and detailed"
        
        print(f"ğŸ”„ æ‰§è¡Œè§†è§’è½¬æ¢: {target_view}")
        return self.edit_image(image, edit_prompt, **kwargs)
    
    def style_transform(
        self,
        image: Union[str, Image.Image],
        target_style: str,
        **kwargs
    ) -> Dict[str, Any]:
        """é£æ ¼è½¬æ¢"""
        style_prompts = self.editing_templates["é£æ ¼è½¬æ¢"]
        
        if target_style in style_prompts:
            edit_prompt = style_prompts[target_style]
        else:
            edit_prompt = f"Convert the image to {target_style} style"
        
        print(f"ğŸ¨ æ‰§è¡Œé£æ ¼è½¬æ¢: {target_style}")
        return self.edit_image(image, edit_prompt, **kwargs)
    
    def environment_transform(
        self,
        image: Union[str, Image.Image],
        target_environment: str,
        **kwargs
    ) -> Dict[str, Any]:
        """ç¯å¢ƒå˜æ¢"""
        env_prompts = self.editing_templates["ç¯å¢ƒå˜æ¢"]
        
        if target_environment in env_prompts:
            edit_prompt = env_prompts[target_environment]
        else:
            edit_prompt = f"Change the environment to {target_environment}"
        
        print(f"ğŸŒ æ‰§è¡Œç¯å¢ƒå˜æ¢: {target_environment}")
        return self.edit_image(image, edit_prompt, **kwargs)
    
    def object_transform(
        self,
        image: Union[str, Image.Image],
        transform_type: str,
        transform_value: str,
        **kwargs
    ) -> Dict[str, Any]:
        """å¯¹è±¡å˜æ¢"""
        obj_prompts = self.editing_templates["å¯¹è±¡å˜æ¢"]
        
        if transform_type in obj_prompts:
            # æ›¿æ¢æ¨¡æ¿ä¸­çš„å ä½ç¬¦
            if "{color}" in obj_prompts[transform_type]:
                edit_prompt = obj_prompts[transform_type].format(color=transform_value)
            elif "{material}" in obj_prompts[transform_type]:
                edit_prompt = obj_prompts[transform_type].format(material=transform_value)
            elif "{size}" in obj_prompts[transform_type]:
                edit_prompt = obj_prompts[transform_type].format(size=transform_value)
            elif "{decoration}" in obj_prompts[transform_type]:
                edit_prompt = obj_prompts[transform_type].format(decoration=transform_value)
            elif "{expression}" in obj_prompts[transform_type]:
                edit_prompt = obj_prompts[transform_type].format(expression=transform_value)
            elif "{pose}" in obj_prompts[transform_type]:
                edit_prompt = obj_prompts[transform_type].format(pose=transform_value)
            elif "{clothing}" in obj_prompts[transform_type]:
                edit_prompt = obj_prompts[transform_type].format(clothing=transform_value)
            else:
                edit_prompt = obj_prompts[transform_type]
        else:
            edit_prompt = f"Change the {transform_type} to {transform_value}"
        
        print(f"ğŸ”§ æ‰§è¡Œå¯¹è±¡å˜æ¢: {transform_type} -> {transform_value}")
        return self.edit_image(image, edit_prompt, **kwargs)
    
    def create_comparison_grid(
        self,
        original_image: Image.Image,
        edited_images: List[Image.Image],
        labels: List[str] = None
    ) -> Image.Image:
        """åˆ›å»ºç¼–è¾‘å‰åå¯¹æ¯”ç½‘æ ¼"""
        all_images = [original_image] + edited_images
        all_labels = ["åŸå›¾"] + (labels or [f"ç¼–è¾‘ {i+1}" for i in range(len(edited_images))])
        
        # è®¡ç®—ç½‘æ ¼å¤§å°
        cols = min(3, len(all_images))
        rows = (len(all_images) + cols - 1) // cols
        
        # ç»Ÿä¸€å›¾åƒå°ºå¯¸
        target_size = (512, 512)
        resized_images = [img.resize(target_size, Image.Resampling.LANCZOS) for img in all_images]
        
        # åˆ›å»ºç½‘æ ¼ç”»å¸ƒ
        grid_width = cols * target_size[0]
        grid_height = rows * target_size[1] + 50 * rows  # ä¸ºæ ‡ç­¾ç•™å‡ºç©ºé—´
        grid_image = Image.new('RGB', (grid_width, grid_height), color='white')
        
        # ç²˜è´´å›¾åƒåˆ°ç½‘æ ¼
        for idx, (image, label) in enumerate(zip(resized_images, all_labels)):
            row = idx // cols
            col = idx % cols
            
            x = col * target_size[0]
            y = row * (target_size[1] + 50)
            
            grid_image.paste(image, (x, y))
            
            # æ·»åŠ æ ‡ç­¾ï¼ˆç®€å•å®ç°ï¼Œå®é™…åº”ç”¨ä¸­å¯ä½¿ç”¨PIL.ImageDraw.textï¼‰
            # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…æ ‡ç­¾éœ€è¦æ›´å¤æ‚çš„æ–‡å­—æ¸²æŸ“
        
        return grid_image
    
    def cleanup_model(self, model_type=None):
        """æ¸…ç†æ¨¡å‹é‡Šæ”¾æ˜¾å­˜"""
        if model_type is None:
            # æ¸…ç†æ‰€æœ‰æ¨¡å‹
            for key, pipeline in self.pipelines.items():
                if pipeline is not None:
                    del pipeline
                    self.pipelines[key] = None
            print("ğŸ§¹ æ‰€æœ‰ç¼–è¾‘æ¨¡å‹å·²æ¸…ç†ï¼Œæ˜¾å­˜å·²é‡Šæ”¾")
        else:
            # æ¸…ç†æŒ‡å®šæ¨¡å‹
            if self.pipelines.get(model_type) is not None:
                del self.pipelines[model_type]
                self.pipelines[model_type] = None
                print(f"ğŸ§¹ {model_type}ç¼–è¾‘æ¨¡å‹å·²æ¸…ç†ï¼Œæ˜¾å­˜å·²é‡Šæ”¾")
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    def load_sam_model(self):
        """åŠ è½½SAMåˆ†å‰²æ¨¡å‹"""
        if not SAM_AVAILABLE:
            print("âš ï¸ SAMä¾èµ–æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨å¯¹è±¡åˆ†å‰²åŠŸèƒ½")
            return False
        
        if self.sam_predictor is not None:
            return True
        
        try:
            print("ğŸ”„ æ­£åœ¨åŠ è½½SAMåˆ†å‰²æ¨¡å‹...")
            model_type = "vit_h"  # æˆ– vit_l, vit_b
            sam = sam_model_registry[model_type](checkpoint="sam_vit_h_4b8939.pth")
            sam.to(device=self.device)
            self.sam_predictor = SamPredictor(sam)
            print("âœ… SAMåˆ†å‰²æ¨¡å‹åŠ è½½å®Œæˆ")
            return True
        except Exception as e:
            print(f"âŒ SAMæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def generate_avatar(
        self,
        avatar_type: str,
        description: str = "",
        style: str = "realistic",
        **kwargs
    ) -> Dict[str, Any]:
        """è™šæ‹Ÿå½¢è±¡ç”Ÿæˆ"""
        # åŠ è½½ç”Ÿæˆæ¨¡å‹
        self.load_pipeline('qwen_edit')
        
        avatar_prompts = self.editing_templates["è™šæ‹Ÿå½¢è±¡ç”Ÿæˆ"]
        
        if avatar_type in avatar_prompts:
            base_prompt = avatar_prompts[avatar_type]
        else:
            base_prompt = f"Generate {avatar_type} avatar"
        
        # ç»„åˆæè¿°
        if description:
            prompt = f"{base_prompt}, {description}"
        else:
            prompt = base_prompt
            
        print(f"ğŸ‘¤ å¼€å§‹ç”Ÿæˆè™šæ‹Ÿå½¢è±¡: {avatar_type}")
        print(f"ğŸ“ ç”Ÿæˆæè¿°: {prompt}")
        
        # åˆ›å»ºåŸºç¡€ç”»å¸ƒ
        canvas = Image.new('RGB', (512, 512), color=(255, 255, 255))
        
        return self.edit_image(canvas, prompt, **kwargs)
    
    def ai_remove(
        self,
        image: Union[str, Image.Image],
        remove_type: str,
        target_object: str = "",
        **kwargs
    ) -> Dict[str, Any]:
        """AIæ¶ˆé™¤åŠŸèƒ½"""
        # åŠ è½½ä¿®å¤æ¨¡å‹
        self.load_pipeline('inpaint')
        
        remove_prompts = self.editing_templates["AIæ¶ˆé™¤"]
        
        if remove_type in remove_prompts:
            if "{object}" in remove_prompts[remove_type]:
                prompt = remove_prompts[remove_type].format(object=target_object)
            else:
                prompt = remove_prompts[remove_type]
        else:
            prompt = f"Remove {remove_type} from the image"
        
        print(f"ğŸ—‘ï¸ æ‰§è¡ŒAIæ¶ˆé™¤: {remove_type}")
        if target_object:
            print(f"ğŸ¯ ç›®æ ‡å¯¹è±¡: {target_object}")
        
        # å¤„ç†è¾“å…¥å›¾åƒ
        if isinstance(image, str):
            input_image = Image.open(image).convert("RGB")
        else:
            input_image = image.convert("RGB")
        
        # ç”Ÿæˆæ©ç  - è¿™é‡Œéœ€è¦æ›´å¤æ‚çš„å®ç°
        # ç®€åŒ–ç‰ˆæœ¬ï¼šåˆ›å»ºåŸºç¡€æ©ç 
        mask = Image.new('L', input_image.size, 0)
        
        try:
            # ä½¿ç”¨inpaintingæ¨¡å‹
            with torch.inference_mode():
                result = self.pipelines['inpaint'](
                    prompt="",  # ç©ºæç¤ºè¯è¡¨ç¤ºç§»é™¤
                    image=input_image,
                    mask_image=mask,
                    generator=torch.manual_seed(kwargs.get('seed', 42)),
                    **{k: v for k, v in kwargs.items() if k in ['num_inference_steps', 'guidance_scale']}
                )
                edited_image = result.images[0]
            
            # ä¿å­˜ç»“æœ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"ai_removed_{timestamp}.png"
            output_path = os.path.join(self.output_dir, filename)
            edited_image.save(output_path)
            
            return {
                "original_image": input_image,
                "edited_image": edited_image,
                "output_path": output_path,
                "metadata": {
                    "operation": "ai_remove",
                    "remove_type": remove_type,
                    "target_object": target_object,
                    "edited_at": datetime.now().isoformat()
                }
            }
        except Exception as e:
            print(f"âŒ AIæ¶ˆé™¤å¤±è´¥: {e}")
            raise e
    
    def ai_redraw(
        self,
        image: Union[str, Image.Image],
        redraw_type: str,
        description: str,
        **kwargs
    ) -> Dict[str, Any]:
        """AIé‡ç»˜åŠŸèƒ½"""
        # åŠ è½½é‡ç»˜æ¨¡å‹
        self.load_pipeline('inpaint_xl')
        
        redraw_prompts = self.editing_templates["AIé‡ç»˜"]
        
        if redraw_type in redraw_prompts:
            if any(placeholder in redraw_prompts[redraw_type] for placeholder in ['{description}', '{background}', '{features}', '{new_object}', '{style}']):
                prompt = redraw_prompts[redraw_type].format(
                    description=description,
                    background=description,
                    features=description,
                    new_object=description,
                    style=description
                )
            else:
                prompt = f"{redraw_prompts[redraw_type]}, {description}"
        else:
            prompt = f"Redraw {redraw_type} as {description}"
        
        print(f"ğŸ¨ æ‰§è¡ŒAIé‡ç»˜: {redraw_type}")
        print(f"ğŸ“ é‡ç»˜æè¿°: {description}")
        
        return self.edit_image(image, prompt, **kwargs)
    
    def virtual_scene(
        self,
        image: Union[str, Image.Image],
        scene_type: str,
        scene_elements: str = "",
        **kwargs
    ) -> Dict[str, Any]:
        """è™šæ‹Ÿåœºæ™¯ç”Ÿæˆ"""
        scene_prompts = self.editing_templates["è™šæ‹Ÿåœºæ™¯"]
        
        if scene_type in scene_prompts:
            if "{period}" in scene_prompts[scene_type]:
                prompt = scene_prompts[scene_type].format(period=scene_elements)
            elif "{elements}" in scene_prompts[scene_type]:
                prompt = scene_prompts[scene_type].format(elements=scene_elements)
            elif "{room_type}" in scene_prompts[scene_type]:
                prompt = scene_prompts[scene_type].format(room_type=scene_elements)
            else:
                prompt = scene_prompts[scene_type]
        else:
            prompt = f"Transform into {scene_type} scene"
        
        if scene_elements and "{" not in scene_prompts.get(scene_type, ""):
            prompt = f"{prompt} with {scene_elements}"
        
        print(f"ğŸŒ ç”Ÿæˆè™šæ‹Ÿåœºæ™¯: {scene_type}")
        
        return self.edit_image(image, prompt, **kwargs)
    
    def outfit_simulation(
        self,
        image: Union[str, Image.Image],
        outfit_type: str,
        outfit_details: str,
        **kwargs
    ) -> Dict[str, Any]:
        """ç©¿æ­æ¨¡æ‹ŸåŠŸèƒ½"""
        outfit_prompts = self.editing_templates["ç©¿æ­æ¨¡æ‹Ÿ"]
        
        if outfit_type in outfit_prompts:
            prompt = outfit_prompts[outfit_type].format(
                clothing_style=outfit_details,
                accessories=outfit_details,
                hairstyle=outfit_details,
                makeup_style=outfit_details,
                color_theme=outfit_details,
                season=outfit_details
            )
        else:
            prompt = f"Change {outfit_type} to {outfit_details}"
        
        print(f"ğŸ‘— æ‰§è¡Œç©¿æ­æ¨¡æ‹Ÿ: {outfit_type}")
        print(f"ğŸ‘” ç©¿æ­è¯¦æƒ…: {outfit_details}")
        
        return self.edit_image(image, prompt, **kwargs)
    
    def text_design(
        self,
        image: Union[str, Image.Image],
        text_type: str,
        text_content: str,
        font_style: str = "modern",
        **kwargs
    ) -> Dict[str, Any]:
        """æ–‡å­—è®¾è®¡åŠŸèƒ½"""
        text_prompts = self.editing_templates["æ–‡å­—è®¾è®¡"]
        
        if text_type in text_prompts:
            prompt = text_prompts[text_type].format(
                text=text_content,
                font_style=font_style,
                title=text_content,
                logo_text=text_content,
                calligraphy_style=font_style
            )
        else:
            prompt = f"Add {text_type} text '{text_content}' with {font_style} style"
        
        print(f"ğŸ“ æ‰§è¡Œæ–‡å­—è®¾è®¡: {text_type}")
        print(f"âœï¸ æ–‡å­—å†…å®¹: {text_content}")
        
        return self.edit_image(image, prompt, **kwargs)
    
    def poster_design(
        self,
        image: Union[str, Image.Image],
        poster_type: str,
        theme: str = "",
        **kwargs
    ) -> Dict[str, Any]:
        """æµ·æŠ¥ç¼–è¾‘åŠŸèƒ½"""
        poster_prompts = self.editing_templates["æµ·æŠ¥ç¼–è¾‘"]
        
        if poster_type in poster_prompts:
            if "{theme}" in poster_prompts[poster_type]:
                prompt = poster_prompts[poster_type].format(theme=theme)
            elif "{event_type}" in poster_prompts[poster_type]:
                prompt = poster_prompts[poster_type].format(event_type=theme)
            else:
                prompt = poster_prompts[poster_type]
        else:
            prompt = f"Design {poster_type} poster"
        
        if theme and "{" not in poster_prompts.get(poster_type, ""):
            prompt = f"{prompt} with {theme} theme"
        
        print(f"ğŸª è®¾è®¡æµ·æŠ¥: {poster_type}")
        if theme:
            print(f"ğŸ¨ ä¸»é¢˜: {theme}")
        
        return self.edit_image(image, prompt, **kwargs)
    
    def get_available_templates(self) -> Dict[str, List[str]]:
        """è·å–å¯ç”¨çš„ç¼–è¾‘æ¨¡æ¿"""
        templates = {}
        for category, prompts in self.editing_templates.items():
            templates[category] = list(prompts.keys())
        return templates